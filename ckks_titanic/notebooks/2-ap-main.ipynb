{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import tenseal as ts\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.chdir(\"..\")\n",
    "from src.features import build_features\n",
    "from models import encrypted_LR\n",
    "from models import unencrypted_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# definition of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = \"\\\\data\\\\raw\\\\\"            # whole data set\n",
    "DATA_PATH = \"/data/quick_demo/\"   # subset of the data set, with 15 train_samples and 5 test_samples\n",
    "#DATA_PATH = \"/home/apignet/homomorphic-encryption/ckks_titanic/data/quick_demo/\"   # subset of the data set, with 400 train_samples and 50 test_samples\n",
    "LOG_PATH = \"reports/log\"\n",
    "LOG_FILENAME = \"test_0716\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileHandler = logging.FileHandler(\"{0}/{1}.log\".format(LOG_PATH, LOG_FILENAME))\n",
    "streamHandler = logging.StreamHandler(sys.stdout)\n",
    "logging.basicConfig(format=\"%(asctime)s  [%(levelname)-8.8s]  %(message)s\", datefmt='%m/%d/%Y %I:%M:%S %p', level = logging.DEBUG, handlers=[fileHandler, streamHandler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1000\n",
    "LEARNING_RATE = 0.5\n",
    "REGULARIZATION_RATE = 0.5\n",
    "VERBOSE = 20\n",
    "SAVE_WEIGHT = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crytp_array(X, local_context):\n",
    "    \"\"\"\n",
    "    This function encrypt a list of vector\n",
    "    \n",
    "    :parameters \n",
    "    ------------\n",
    "    \n",
    "    :param X ; list of list, interpreted as list of vector to encrypt\n",
    "    :param local_context ; TenSEAL context object used to encrypt\n",
    "    \n",
    "    :returns\n",
    "    ------------\n",
    "    \n",
    "    list ; list of CKKS ciphertext  \n",
    "    \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(len(X)):\n",
    "        res.append(ts.ckks_vector(local_context, X[i]))\n",
    "        if i == len(X) // 4:\n",
    "            logging.info(\"25 % ...\")\n",
    "        elif i == len(X) // 2 :\n",
    "            logging.info(\"50 % ...\")\n",
    "        elif i == 3* len(X)//4:\n",
    "            logging.info(\"75% ...\")\n",
    "    return res\n",
    "\n",
    "def encryption_error(encrypted_weight,encrypted_bias, unencrypted_weight, unencrypted_bias, secret_key=None):\n",
    "    \n",
    "    def err(encrypted_weight,encrypted_bias, unencrypted_weight, unencrypted_bias, secret_key=secret_key):\n",
    "        if secret_key is None:\n",
    "            return (np.sum(np.power((np.array(encrypted_weight.decrypt()) - unencrypted_weight), 2)) + np.power((np.array(encrypted_bias.decrypt()) - unencrypted_bias), 2)) / (np.sum(np.power(unencrypted_weight, 2)) + np.power(unencrypted_bias,2))\n",
    "        else:\n",
    "            return (np.sum(np.power((np.array(encrypted_weight.decrypt(secret_key)) - unencrypted_weight), 2)) + np.power((np.array(encrypted_bias.decrypt(secret_key)) - unencrypted_bias), 2)) / (np.sum(np.power(unencrypted_weight, 2)) + np.power(unencrypted_bias,2))\n",
    "    \n",
    "    \n",
    "    res = [0 for _ in range(len(encrypted_bias))]\n",
    "    for i in range(len(encrypted_bias)):\n",
    "        res[i]=err(encrypted_weight[i], encrypted_bias[i],unencrypted_weight[i], unencrypted_bias[i], secret_key=secret_key)\n",
    "        \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidential functions\n",
    "\n",
    "These functions involves security breachs (as use of unencrypted data, or decryption of weights) and cannot be coded by Alice.\n",
    "However, the functions encapslulate the unsafe process, so can be performed by Alice if Bob provides them. \n",
    "Therefore, they are currently passed as parameters to Alice, which only calls them.\n",
    "\n",
    "Currently there is a huge security breach, as confidential parameters (security key for instance), which are needed by those functions, are passed in a dictionnary to Alice. \n",
    "For a safe protocole, we have to change these functions, to set up a safe communication protocole between Bob and Alice.\n",
    "Alice will therefore only send the crypted data to Bob (using these functions, in which can be set up the communication process) and Bob will locally perform the functions which are currently coded bellow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh(ciphertext, **kwarg):\n",
    "    \"\"\"\n",
    "    This function is here to refresh a ciphertext. This operation reset to 0 the calculus depth of the input ciphertext \n",
    "    WARNING :  Basically the function decryt and re-encrypt the ciphertext. \n",
    "    This is not safe, this operation needs to be done by a trusted part \n",
    "    (Bob for the perfect instance, even if it requieres communications between Alice and Bob while training)\n",
    "    \n",
    "    :parameters \n",
    "    ------------\n",
    "    \n",
    "    ciphertext ; encrypted CKKS vector \n",
    "    **kwarg ; dict, must contain context and secret_key.\n",
    "    \n",
    "    :returns\n",
    "    ------------\n",
    "    \n",
    "    ciphertext : encrypted CKKS vector \n",
    "    \n",
    "    \"\"\"\n",
    "    context = kwarg.get(\"context\", None)\n",
    "    secret_key = kwarg.get(\"secret_key\", None)\n",
    "    assert context , \"Context must be provided with the key : context\"+str(context)\n",
    "    if context.is_private():\n",
    "        return ts.ckks_vector(context, ciphertext.decrypt())\n",
    "    else : \n",
    "        if not secret_key:\n",
    "            raise AttributeError(\"The secret key is not provided and the context provided is public, decryption is not possible\")\n",
    "        else:\n",
    "            return ts.ckks_vector(context, ciphertext.decrypt(secret_key))\n",
    "   \n",
    "            \n",
    "def accuracy(crypted_weight, crypted_bias, prior_unencrypted_X = None, prior_unencrypted_Y=None, **kwarg):\n",
    "    \"\"\"\n",
    "    This function is here to compute the accuracy\n",
    "    1-NOTE : we could maybe estimate this function homomorphically, by designing an approximation of the sign function. \n",
    "    However, this kind of approximation seems really hard to set up \n",
    "    Therefore, we will not be able to use the metric, as the result is encrypted.\n",
    "    2-NOTE : this function could be parallelized, as we do not need the result for the next epoch. \n",
    "    \n",
    "    :parameters \n",
    "    ------------\n",
    "    \n",
    "    crypted_weight ; encrypted CKKS vector (size equal to the number of features)\n",
    "    crypted_bias ; encrypted CKKS vector (size 1)\n",
    "    (Optionnal) prior_unencrypted_X ; samples on which the model accuracy will be computed. \n",
    "                                If not provided, the accuracy will be computed with the data provided in the kwarg\n",
    "    (Optionnal) prior_unencrypted_Y ; labels on which the model accuracy will be computed. If not provided.\n",
    "                                If not provided, the accuracy will be computed with the data provided in the kwarg\n",
    "    **kwarg ; dict, must contain context, secret_key, (Optionnal) unencrytped_X and (Optionnal) unencrypted_Y \n",
    "    \n",
    "    :returns\n",
    "    ------------\n",
    "    \n",
    "    accuray : float (rounded to 2 digits)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    context = kwarg.get(\"context\", None)\n",
    "    if not context:\n",
    "        raise AttributeError(\"Context must be provided in the **kwarg, with the key : context\")\n",
    "    secret_key = kwarg.get(\"secret_key\", None)\n",
    "    if prior_unencrypted_X is None:\n",
    "        unencrypted_X = kwarg.get(\"unencrypted_X\", None)\n",
    "        if unencrypted_X is None:\n",
    "            raise AttributeError(\"Unencrypted samples must be provided, either in the arguments, or in the **kwarg, with the key : unencrypted_X\")\n",
    "    else:\n",
    "        unencrypted_X = np.array(prior_unencrypted_X)\n",
    "    if prior_unencrypted_Y is None:\n",
    "        unencrypted_Y = kwarg.get(\"unencrypted_Y\", None)\n",
    "        if unencrypted_Y is None:\n",
    "            raise AttributeError(\"Unencrypted labels must be provided, either in the arguments, or in the **kwarg, with the key : unencrypted_Y\")\n",
    "    else:\n",
    "        unencrypted_Y = np.array(prior_unencrypted_Y)\n",
    "    if context.is_private():\n",
    "            weight = np.array(crypted_weight.decrypt())\n",
    "            bias = np.array(crypted_bias.decrypt())\n",
    "    else : \n",
    "        if not secret_key:\n",
    "            raise AttributeError(\"The secret key is not provided and the context provided is public, decryption is not possible. Pass a private context or the secret key\")\n",
    "        else:\n",
    "            weight = np.array(crypted_weight.decrypt(secret_key))\n",
    "            bias = np.array(crypted_bias.decrypt(secret_key))\n",
    "            \n",
    "    re = unencrypted_X.dot(weight) + bias  \n",
    "    prediction = (np.float_power(re, 3)) * -0.004 + re * 0.197 + 0.5\n",
    "    print(prediction)\n",
    "    return (np.abs((unencrypted_Y-prediction.reshape(unencrypted_Y.shape))) < 0.5).astype(float).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "logging.info(os.getcwd())\n",
    "raw_train, raw_test = build_features.data_import(os.getcwd()+DATA_PATH)\n",
    "train, submission_test = build_features.processing(raw_train, raw_test)\n",
    "del submission_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "train, test = train_test_split(train, test_size=0.15)\n",
    "train_labels = train.Survived\n",
    "test_labels = test.Survived\n",
    "train_features = train.drop(\"Survived\", axis=1)\n",
    "test_features = test.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of safety parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "logging.info('Definition of safety parameters...')\n",
    "timer = time.time()\n",
    "# context = ts.context(ts.SCHEME_TYPE.CKKS, 32768,\n",
    "# coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 60])\n",
    "#context = ts.context(ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[40, 21, 21, 21, 21, 21, 21, 40])\n",
    "\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, 16384, coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 40, 40, 40, 60])\n",
    "context.global_scale = pow(2, 40)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "logging.info('Generation of the Galois Key...')\n",
    "timer = time.time()\n",
    "context.generate_galois_keys()\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "\n",
    "#logging.info('Generation of the secret key...')\n",
    "#timer = time.time()\n",
    "secret_key = context.secret_key()\n",
    "#context.make_context_public()\n",
    "#logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "#if context.is_public():\n",
    "#    logging.info(\"The context is now public, the context do not hold the secret key anymore, and decrypt methods need the secret key to be provide,\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "logging.info(\"Data encryption...\")\n",
    "timer = time.time()\n",
    "encrypted_X = crytp_array(train_features.to_numpy(), context)\n",
    "encrypted_Y = crytp_array(train_labels.to_numpy().reshape((-1, 1)), context)\n",
    "encrypted_test_X = crytp_array(test_features.to_numpy(), context)\n",
    "encrypted_test_Y = crytp_array(test_labels.to_numpy().reshape((-1, 1)), context)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the weight\n",
    "\n",
    "The weights have to be crypted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "unencrypted_weight = np.random.normal(loc=0,\n",
    "                                      scale=0.2, size =(train_features.to_numpy().shape[1]))\n",
    "logging.info(unencrypted_weight)\n",
    "weight = ts.ckks_vector(context, unencrypted_weight)\n",
    "unencrypted_weight = np.array(unencrypted_weight)\n",
    "unencrypted_bias = np.random.random((1))\n",
    "bias = ts.ckks_vector(context, unencrypted_bias)\n",
    "unencrypted_bias = np.array(unencrypted_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidential data as yet stored into a dictionnary, and will be used during the training only by functions which are passed as arguments to the fit methods. This encapsulation of sensitive data will allows us to ensure security during training later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "confidential_data = {'context':context,\n",
    "                     'secret_key':secret_key, \n",
    "                     'unencrypted_X':train_features.to_numpy(),\n",
    "                     'unencrypted_Y':train_labels.to_numpy().reshape((-1, 1)) \n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "weight.dot(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the crypted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Model initialization\")\n",
    "model = encrypted_LR.LogisticRegressionHE(init_weight=weight,\n",
    "                                          init_bias=bias,\n",
    "                                          refresh_function=refresh, \n",
    "                                          confidential_kwarg=confidential_data,\n",
    "                                          accuracy=accuracy,\n",
    "                                          verbose=VERBOSE,\n",
    "                                          save_weight=SAVE_WEIGHT,\n",
    "                                          max_epoch=EPOCH,\n",
    "                                          lr=LEARNING_RATE,\n",
    "                                          reg_para=REGULARIZATION_RATE,\n",
    "                                          n_jobs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Training starting\")\n",
    "timer=time.time()\n",
    "%prun model.fit(encrypted_X, encrypted_Y)\n",
    "logging.info(\"Training done. \" + str(round(time.time() - timer, 0)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model.accuracy(unencrypted_X=test_features.to_numpy(), unencrypted_Y=test_labels.to_numpy().reshape((-1, 1)))\n",
    "print(test_labels.to_numpy())\n",
    "logging.info(\"Accuracy of encrypted model : %s \" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the unencrypted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Model initialization\")\n",
    "unencrypted_model = unencrypted_LR.LogisticRegression(init_weight=unencrypted_weight,\n",
    "                                                      init_bias=unencrypted_bias,\n",
    "                                                      verbose=VERBOSE,\n",
    "                                                      save_weight= SAVE_WEIGHT,\n",
    "                                                      max_epoch=EPOCH,\n",
    "                                                      lr=LEARNING_RATE,\n",
    "                                                      reg_para=REGULARIZATION_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Training starting\")\n",
    "timer=time.time()\n",
    "unencrypted_model.fit(train_features.to_numpy(), train_labels.to_numpy().reshape((-1, 1)))\n",
    "logging.info(\"Training done. \" + str(round(time.time() - timer, 0)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = unencrypted_model.accuracy(test_features.to_numpy(), test_labels.to_numpy().reshape((-1, 1)))\n",
    "logging.info(\"Accuracy of unencrypted model : %s \" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unencrypted_model.true_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unencrypted_model.weight.dot(unencrypted_model.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encrypted and unencrypted losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i*VERBOSE for i in range(len(model.loss_list))], [i.decrypt()[0] for i in model.loss_list], label='cipherloss')\n",
    "plt.plot([i*VERBOSE for i in range(len(unencrypted_model.loss_list))], unencrypted_model.loss_list, label='plainloss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Losses evolution of both models')\n",
    "plt.legend(loc='best')\n",
    "[i.decrypt()[0] for i in model.loss_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unencrypted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i*VERBOSE for i in range(len(unencrypted_model.loss_list))], np.array(unencrypted_model.loss_list).reshape((-1)))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss evolution of unencrypted model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logging.info(\"Model initialization\")\n",
    "unencrypted_model = unencrypted_LR.LogisticRegression(init_weight=unencrypted_weight,\n",
    "                                                      init_bias=unencrypted_bias,\n",
    "                                                      verbose=VERBOSE,\n",
    "                                                      save_weight= SAVE_WEIGHT,\n",
    "                                                      max_epoch==EPOCH,\n",
    "                                                      lr=LEARNING_RATE,\n",
    "                                                      reg_para=REGULARIZATION_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative error between losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypted = [i.decrypt()[0] for i in model.loss_list]\n",
    "true_err = np.abs(np.array(decrypted) - np.array(unencrypted_model.loss_list))\n",
    "rel_err = true_err/np.linalg.norm(decrypted)\n",
    "rel_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot([i*VERBOSE for i in range(len(model.loss_list))],  rel_err)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Relative error on loss')\n",
    "plt.title('Relative error between encrypted loss and unencrypted loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative error between weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = encryption_error(model.weight_list,model.bias_list, unencrypted_model.weight_list,unencrypted_model.bias_list)\n",
    "plt.plot([i*VERBOSE for i in range(len(error_list))], error_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Relative error on weights')\n",
    "plt.title('Relative error between encrypted weights and unencrypted weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TenSEAL",
   "language": "python",
   "name": "tenseal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
