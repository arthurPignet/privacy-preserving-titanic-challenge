{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import tenseal as ts\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.chdir(\"/home/apignet/homomorphic-encryption/ckks_titanic\")\n",
    "from src.features import build_features\n",
    "from models import encrypted_LR\n",
    "from models import unencrypted_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# definition of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"~/homomorphic-encryption/ckks_titanic/data/raw/\"            # whole data set\n",
    "#DATA_PATH = \"/home/apignet/homomorphic-encryption/ckks_titanic/data/quick_demo/\"   # subset of the data set, with 15 train_samples and 5 test_samples\n",
    "#DATA_PATH = \"/home/apignet/homomorphic-encryption/ckks_titanic/data/quick_demo/\"   # subset of the data set, with 400 train_samples and 50 test_samples\n",
    "LOG_PATH = \"reports/log\"\n",
    "LOG_FILENAME = \"test_0716\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileHandler = logging.FileHandler(\"{0}/{1}.log\".format(LOG_PATH, LOG_FILENAME))\n",
    "streamHandler = logging.StreamHandler(sys.stdout)\n",
    "logging.basicConfig(format=\"%(asctime)s  [%(levelname)-8.8s]  %(message)s\", datefmt='%m/%d/%Y %I:%M:%S %p', level = logging.DEBUG, handlers=[fileHandler, streamHandler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1000\n",
    "LEARNING_RATE = 0.5\n",
    "REGULARIZATION_RATE = 0.5\n",
    "VERBOSE = 20\n",
    "SAVE_WEIGHT = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crytp_array(X, local_context):\n",
    "    \"\"\"\n",
    "    This function encrypt a list of vector\n",
    "    \n",
    "    :parameters \n",
    "    ------------\n",
    "    \n",
    "    :param X ; list of list, interpreted as list of vector to encrypt\n",
    "    :param local_context ; TenSEAL context object used to encrypt\n",
    "    \n",
    "    :returns\n",
    "    ------------\n",
    "    \n",
    "    list ; list of CKKS ciphertext  \n",
    "    \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(len(X)):\n",
    "        res.append(ts.ckks_vector(local_context, X[i]))\n",
    "        if i == len(X) // 4:\n",
    "            logging.info(\"25 % ...\")\n",
    "        elif i == len(X) // 2 :\n",
    "            logging.info(\"50 % ...\")\n",
    "        elif i == 3* len(X)//4:\n",
    "            logging.info(\"75% ...\")\n",
    "    return res\n",
    "\n",
    "def encryption_error(encrypted_weight,encrypted_bias, unencrypted_weight, unencrypted_bias, secret_key=None):\n",
    "    \n",
    "    def err(encrypted_weight,encrypted_bias, unencrypted_weight, unencrypted_bias, secret_key=secret_key):\n",
    "        if secret_key is None:\n",
    "            return (np.sum(np.power((np.array(encrypted_weight.decrypt()) - unencrypted_weight), 2)) + np.power((np.array(encrypted_bias.decrypt()) - unencrypted_bias), 2)) / (np.sum(np.power(unencrypted_weight, 2)) + np.power(unencrypted_bias,2))\n",
    "        else:\n",
    "            return (np.sum(np.power((np.array(encrypted_weight.decrypt(secret_key)) - unencrypted_weight), 2)) + np.power((np.array(encrypted_bias.decrypt(secret_key)) - unencrypted_bias), 2)) / (np.sum(np.power(unencrypted_weight, 2)) + np.power(unencrypted_bias,2))\n",
    "    \n",
    "    \n",
    "    res = [0 for _ in range(len(encrypted_bias))]\n",
    "    for i in range(len(encrypted_bias)):\n",
    "        res[i]=err(encrypted_weight[i], encrypted_bias[i],unencrypted_weight[i], unencrypted_bias[i], secret_key=secret_key)\n",
    "        \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidential functions\n",
    "\n",
    "These functions involves security breachs (as use of unencrypted data, or decryption of weights) and cannot be coded by Alice.\n",
    "However, the functions encapslulate the unsafe process, so can be performed by Alice if Bob provides them. \n",
    "Therefore, they are currently passed as parameters to Alice, which only calls them.\n",
    "\n",
    "Currently there is a huge security breach, as confidential parameters (security key for instance), which are needed by those functions, are passed in a dictionnary to Alice. \n",
    "For a safe protocole, we have to change these functions, to set up a safe communication protocole between Bob and Alice.\n",
    "Alice will therefore only send the crypted data to Bob (using these functions, in which can be set up the communication process) and Bob will locally perform the functions which are currently coded bellow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh(ciphertext, **kwarg):\n",
    "    \"\"\"\n",
    "    This function is here to refresh a ciphertext. This operation reset to 0 the calculus depth of the input ciphertext \n",
    "    WARNING :  Basically the function decryt and re-encrypt the ciphertext. \n",
    "    This is not safe, this operation needs to be done by a trusted part \n",
    "    (Bob for the perfect instance, even if it requieres communications between Alice and Bob while training)\n",
    "    \n",
    "    :parameters \n",
    "    ------------\n",
    "    \n",
    "    ciphertext ; encrypted CKKS vector \n",
    "    **kwarg ; dict, must contain context and secret_key.\n",
    "    \n",
    "    :returns\n",
    "    ------------\n",
    "    \n",
    "    ciphertext : encrypted CKKS vector \n",
    "    \n",
    "    \"\"\"\n",
    "    context = kwarg.get(\"context\", None)\n",
    "    secret_key = kwarg.get(\"secret_key\", None)\n",
    "    assert context , \"Context must be provided with the key : context\"+str(context)\n",
    "    if context.is_private():\n",
    "        return ts.ckks_vector(context, ciphertext.decrypt())\n",
    "    else : \n",
    "        if not secret_key:\n",
    "            raise AttributeError(\"The secret key is not provided and the context provided is public, decryption is not possible\")\n",
    "        else:\n",
    "            return ts.ckks_vector(context, ciphertext.decrypt(secret_key))\n",
    "   \n",
    "            \n",
    "def accuracy(crypted_weight, crypted_bias, prior_unencrypted_X = None, prior_unencrypted_Y=None, **kwarg):\n",
    "    \"\"\"\n",
    "    This function is here to compute the accuracy\n",
    "    1-NOTE : we could maybe estimate this function homomorphically, by designing an approximation of the sign function. \n",
    "    However, this kind of approximation seems really hard to set up \n",
    "    Therefore, we will not be able to use the metric, as the result is encrypted.\n",
    "    2-NOTE : this function could be parallelized, as we do not need the result for the next epoch. \n",
    "    \n",
    "    :parameters \n",
    "    ------------\n",
    "    \n",
    "    crypted_weight ; encrypted CKKS vector (size equal to the number of features)\n",
    "    crypted_bias ; encrypted CKKS vector (size 1)\n",
    "    (Optionnal) prior_unencrypted_X ; samples on which the model accuracy will be computed. \n",
    "                                If not provided, the accuracy will be computed with the data provided in the kwarg\n",
    "    (Optionnal) prior_unencrypted_Y ; labels on which the model accuracy will be computed. If not provided.\n",
    "                                If not provided, the accuracy will be computed with the data provided in the kwarg\n",
    "    **kwarg ; dict, must contain context, secret_key, (Optionnal) unencrytped_X and (Optionnal) unencrypted_Y \n",
    "    \n",
    "    :returns\n",
    "    ------------\n",
    "    \n",
    "    accuray : float (rounded to 2 digits)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    context = kwarg.get(\"context\", None)\n",
    "    if not context:\n",
    "        raise AttributeError(\"Context must be provided in the **kwarg, with the key : context\")\n",
    "    secret_key = kwarg.get(\"secret_key\", None)\n",
    "    if prior_unencrypted_X is None:\n",
    "        unencrypted_X = kwarg.get(\"unencrypted_X\", None)\n",
    "        if unencrypted_X is None:\n",
    "            raise AttributeError(\"Unencrypted samples must be provided, either in the arguments, or in the **kwarg, with the key : unencrypted_X\")\n",
    "    else:\n",
    "        unencrypted_X = np.array(prior_unencrypted_X)\n",
    "    if prior_unencrypted_Y is None:\n",
    "        unencrypted_Y = kwarg.get(\"unencrypted_Y\", None)\n",
    "        if unencrypted_Y is None:\n",
    "            raise AttributeError(\"Unencrypted labels must be provided, either in the arguments, or in the **kwarg, with the key : unencrypted_Y\")\n",
    "    else:\n",
    "        unencrypted_Y = np.array(prior_unencrypted_Y)\n",
    "    if context.is_private():\n",
    "            weight = np.array(crypted_weight.decrypt())\n",
    "            bias = np.array(crypted_bias.decrypt())\n",
    "    else : \n",
    "        if not secret_key:\n",
    "            raise AttributeError(\"The secret key is not provided and the context provided is public, decryption is not possible. Pass a private context or the secret key\")\n",
    "        else:\n",
    "            weight = np.array(crypted_weight.decrypt(secret_key))\n",
    "            bias = np.array(crypted_bias.decrypt(secret_key))\n",
    "            \n",
    "    re = unencrypted_X.dot(weight) + bias  \n",
    "    prediction = (np.float_power(re, 3)) * -0.004 + re * 0.197 + 0.5\n",
    "    print(prediction)\n",
    "    return (np.abs((unencrypted_Y-prediction.reshape(unencrypted_Y.shape))) < 0.5).astype(float).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 01:59:15 PM  [INFO    ]  /home/apignet/homomorphic-encryption/ckks_titanic\n",
      "07/22/2020 01:59:15 PM  [INFO    ]  loading the data into memory (pandas df)\n",
      "07/22/2020 01:59:15 PM  [INFO    ]  Done\n",
      "07/22/2020 01:59:15 PM  [INFO    ]  making final data set from raw data\n",
      "07/22/2020 01:59:15 PM  [INFO    ]  Done\n"
     ]
    }
   ],
   "source": [
    "logging.info(os.getcwd())\n",
    "raw_train, raw_test = build_features.data_import(DATA_PATH)\n",
    "train, submission_test = build_features.processing(raw_train, raw_test)\n",
    "del submission_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(train, test_size=0.15)\n",
    "train_labels = train.Survived\n",
    "test_labels = test.Survived\n",
    "train_features = train.drop(\"Survived\", axis=1)\n",
    "test_features = test.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of safety parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 01:59:15 PM  [INFO    ]  Definition of safety parameters...\n",
      "07/22/2020 01:59:16 PM  [INFO    ]  Done. 0.47 seconds\n",
      "07/22/2020 01:59:16 PM  [INFO    ]  Generation of the Galois Key...\n",
      "07/22/2020 01:59:21 PM  [INFO    ]  Done. 4.78 seconds\n"
     ]
    }
   ],
   "source": [
    "logging.info('Definition of safety parameters...')\n",
    "timer = time.time()\n",
    "# context = ts.context(ts.SCHEME_TYPE.CKKS, 32768,\n",
    "# coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 60])\n",
    "#context = ts.context(ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[40, 21, 21, 21, 21, 21, 21, 40])\n",
    "\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, 16384, coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 40, 40, 40, 60])\n",
    "context.global_scale = pow(2, 40)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "logging.info('Generation of the Galois Key...')\n",
    "timer = time.time()\n",
    "context.generate_galois_keys()\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "\n",
    "#logging.info('Generation of the secret key...')\n",
    "#timer = time.time()\n",
    "secret_key = context.secret_key()\n",
    "#context.make_context_public()\n",
    "#logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "#if context.is_public():\n",
    "#    logging.info(\"The context is now public, the context do not hold the secret key anymore, and decrypt methods need the secret key to be provide,\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'non' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8fd40cce2c30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data encryption...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mencrypted_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrytp_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencrypted_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrytp_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'non' is not defined"
     ]
    }
   ],
   "source": [
    "non\n",
    "logging.info(\"Data encryption...\")\n",
    "timer = time.time()\n",
    "encrypted_X = crytp_array(train_features.to_numpy(), context)\n",
    "encrypted_Y = crytp_array(train_labels.to_numpy().reshape((-1, 1)), context)\n",
    "encrypted_test_X = crytp_array(test_features.to_numpy(), context)\n",
    "encrypted_test_Y = crytp_array(test_labels.to_numpy().reshape((-1, 1)), context)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the weight\n",
    "\n",
    "The weights have to be crypted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 01:59:46 PM  [INFO    ]  [ 0.16590715 -0.09257374  0.16004964  0.20677976  0.20420528  0.11103851\n",
      "  0.10304017 -0.1453651   0.02528902 -0.05797532  0.04885079  0.09763332\n",
      " -0.16228321  0.04422775  0.22516243  0.30917356  0.1527046  -0.01717296\n",
      " -0.02573226  0.10321369 -0.17275581 -0.30829916 -0.02709776  0.42835689\n",
      " -0.14795147  0.20415788  0.05168477 -0.05935426 -0.0958546  -0.07875969\n",
      "  0.32177547 -0.40583081]\n"
     ]
    }
   ],
   "source": [
    "unencrypted_weight = np.random.normal(loc=0,\n",
    "                                      scale=0.2, size =(train_features.to_numpy().shape[1]))\n",
    "logging.info(unencrypted_weight)\n",
    "weight = ts.ckks_vector(context, unencrypted_weight)\n",
    "unencrypted_weight = np.array(unencrypted_weight)\n",
    "unencrypted_bias = np.random.random((1))\n",
    "bias = ts.ckks_vector(context, unencrypted_bias)\n",
    "unencrypted_bias = np.array(unencrypted_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidential data as yet stored into a dictionnary, and will be used during the training only by functions which are passed as arguments to the fit methods. This encapsulation of sensitive data will allows us to ensure security during training later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidential_data = {'context':context,\n",
    "                     'secret_key':secret_key, \n",
    "                     'unencrypted_X':train_features.to_numpy(),\n",
    "                     'unencrypted_Y':train_labels.to_numpy().reshape((-1, 1)) \n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_tenseal_cpp.CKKSVector at 0x7f8771069998>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.dot(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the crypted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 01:59:48 PM  [INFO    ]  Model initialization\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Model initialization\")\n",
    "model = encrypted_LR.LogisticRegressionHE(init_weight=weight,\n",
    "                                          init_bias=bias,\n",
    "                                          refresh_function=refresh, \n",
    "                                          confidential_kwarg=confidential_data,\n",
    "                                          accuracy=accuracy,\n",
    "                                          verbose=VERBOSE,\n",
    "                                          save_weight=SAVE_WEIGHT,\n",
    "                                          max_epoch=EPOCH,\n",
    "                                          lr=LEARNING_RATE,\n",
    "                                          reg_para=REGULARIZATION_RATE,\n",
    "                                          n_jobs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 01:59:49 PM  [INFO    ]  Training starting\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'encrypted_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a5c63e6e8309>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training starting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prun'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.fit(encrypted_X, encrypted_Y)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training done. \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2305\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2306\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2307\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2308\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/apignet/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-55>\u001b[0m in \u001b[0;36mprun\u001b[0;34m(self, parameter_s, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mprun\u001b[0;34m(self, parameter_s, cell)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0marg_str\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0marg_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_with_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_with_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36m_run_with_profiler\u001b[0;34m(self, code, opts, namespace)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mprof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mprof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0msys_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/cProfile.py\u001b[0m in \u001b[0;36mrunctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encrypted_X' is not defined"
     ]
    }
   ],
   "source": [
    "logging.info(\"Training starting\")\n",
    "timer=time.time()\n",
    "%prun model.fit(encrypted_X, encrypted_Y)\n",
    "logging.info(\"Training done. \" + str(round(time.time() - timer, 0)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59397082 0.58981933 0.54336615 0.56544631 0.65786912 0.58884123\n",
      " 0.84762938 0.76612399 0.52685978 0.71872114 0.70967457 0.6105633\n",
      " 0.48919096 0.6556783  0.64152498 0.706513   0.58976567 0.5790937\n",
      " 0.60679799 0.63753169 0.65331163 0.53776418 0.58336184 0.58395973\n",
      " 0.58765119 0.56783292 0.64636809 0.60385179 0.58754465 0.63145657\n",
      " 0.63318538 0.8454396  0.58252226 0.58031199 0.47231746 0.60189272\n",
      " 0.66208902 0.74023997 0.58876985 0.63112206 0.5798192  0.61657147\n",
      " 0.589918   0.54230011 0.62798291 0.64789329 0.63557064 0.65533211\n",
      " 0.64993826 0.57794485 0.57722339 0.79564739 0.64517146 0.51769199\n",
      " 0.65834818 0.54113065 0.69737555 0.59471028 0.69968503 0.67617219\n",
      " 0.6363054  0.50295508 0.70207668 0.57006149 0.51770668 0.53861354\n",
      " 0.64075638 0.58976567 0.71863494 0.58993965 0.59472871 0.58976567\n",
      " 0.6941927  0.59588772 0.60919959 0.61972125 0.56869486 0.58683001\n",
      " 0.66293256 0.68715312 0.65027307 0.58974393 0.52899922 0.57656956\n",
      " 0.67407899 0.60194617 0.58144127 0.62318429 0.67339447 0.58312404\n",
      " 0.51767438 0.51945126 0.58981933 0.62036396 0.50764624 0.74290417\n",
      " 0.60554568 0.60440772 0.55201165 0.56934843 0.77671248 0.58364108\n",
      " 0.68200863 0.58201521 0.50059171 0.72786975 0.61866683 0.65367722\n",
      " 0.68982072 0.63598483 0.6507179  0.486143   0.58823047 0.60924103\n",
      " 0.58364255 0.58976567 0.59188533 0.59710095 0.72400424 0.48326231\n",
      " 0.53731478 0.59188533 0.71720407 0.45312978 0.55843278 0.55340317\n",
      " 0.78746582 0.69151851 0.58300662 0.58366783 0.55714791 0.59761051\n",
      " 0.66780726 0.60677349]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.]\n",
      "07/22/2020 01:59:51 PM  [INFO    ]  Accuracy of encrypted model : 0.43283582089552236 \n"
     ]
    }
   ],
   "source": [
    "acc = model.accuracy(unencrypted_X=test_features.to_numpy(), unencrypted_Y=test_labels.to_numpy().reshape((-1, 1)))\n",
    "print(test_labels.to_numpy())\n",
    "logging.info(\"Accuracy of encrypted model : %s \" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the unencrypted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 02:12:38 PM  [INFO    ]  Model initialization\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Model initialization\")\n",
    "unencrypted_model = unencrypted_LR.LogisticRegression(init_weight=unencrypted_weight,\n",
    "                                                      init_bias=unencrypted_bias,\n",
    "                                                      verbose=VERBOSE,\n",
    "                                                      save_weight= SAVE_WEIGHT,\n",
    "                                                      max_epoch=EPOCH,\n",
    "                                                      lr=LEARNING_RATE,\n",
    "                                                      reg_para=REGULARIZATION_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 02:12:39 PM  [INFO    ]  Training starting\n",
      "07/22/2020 02:12:39 PM  [INFO    ]  iteration number 1 is starting\n",
      "07/22/2020 02:12:39 PM  [INFO    ]  Loss : [[572.02202431]].\n",
      "07/22/2020 02:12:41 PM  [INFO    ]  iteration number 21 is starting\n",
      "07/22/2020 02:12:41 PM  [INFO    ]  Loss : [[421.70102712]].\n",
      "07/22/2020 02:12:44 PM  [INFO    ]  iteration number 41 is starting\n",
      "07/22/2020 02:12:44 PM  [INFO    ]  Loss : [[424.89217808]].\n",
      "07/22/2020 02:12:46 PM  [INFO    ]  iteration number 61 is starting\n",
      "07/22/2020 02:12:46 PM  [INFO    ]  Loss : [[426.38946601]].\n",
      "07/22/2020 02:12:49 PM  [INFO    ]  iteration number 81 is starting\n",
      "07/22/2020 02:12:49 PM  [INFO    ]  Loss : [[427.05384794]].\n",
      "07/22/2020 02:12:51 PM  [INFO    ]  iteration number 101 is starting\n",
      "07/22/2020 02:12:51 PM  [INFO    ]  Loss : [[427.34276181]].\n",
      "07/22/2020 02:12:54 PM  [INFO    ]  iteration number 121 is starting\n",
      "07/22/2020 02:12:54 PM  [INFO    ]  Loss : [[427.46735204]].\n",
      "07/22/2020 02:12:56 PM  [INFO    ]  iteration number 141 is starting\n",
      "07/22/2020 02:12:56 PM  [INFO    ]  Loss : [[427.52089011]].\n",
      "07/22/2020 02:12:59 PM  [INFO    ]  iteration number 161 is starting\n",
      "07/22/2020 02:12:59 PM  [INFO    ]  Loss : [[427.54386146]].\n",
      "07/22/2020 02:13:01 PM  [INFO    ]  iteration number 181 is starting\n",
      "07/22/2020 02:13:01 PM  [INFO    ]  Loss : [[427.55371133]].\n",
      "07/22/2020 02:13:04 PM  [INFO    ]  iteration number 201 is starting\n",
      "07/22/2020 02:13:04 PM  [INFO    ]  Loss : [[427.55793368]].\n",
      "07/22/2020 02:13:06 PM  [INFO    ]  iteration number 221 is starting\n",
      "07/22/2020 02:13:06 PM  [INFO    ]  Loss : [[427.55974346]].\n",
      "07/22/2020 02:13:09 PM  [INFO    ]  iteration number 241 is starting\n",
      "07/22/2020 02:13:09 PM  [INFO    ]  Loss : [[427.56051913]].\n",
      "07/22/2020 02:13:11 PM  [INFO    ]  iteration number 261 is starting\n",
      "07/22/2020 02:13:11 PM  [INFO    ]  Loss : [[427.56085158]].\n",
      "07/22/2020 02:13:14 PM  [INFO    ]  iteration number 281 is starting\n",
      "07/22/2020 02:13:14 PM  [INFO    ]  Loss : [[427.56099406]].\n",
      "07/22/2020 02:13:16 PM  [INFO    ]  iteration number 301 is starting\n",
      "07/22/2020 02:13:16 PM  [INFO    ]  Loss : [[427.56105512]].\n",
      "07/22/2020 02:13:19 PM  [INFO    ]  iteration number 321 is starting\n",
      "07/22/2020 02:13:19 PM  [INFO    ]  Loss : [[427.56108129]].\n",
      "07/22/2020 02:13:21 PM  [INFO    ]  iteration number 341 is starting\n",
      "07/22/2020 02:13:21 PM  [INFO    ]  Loss : [[427.56109251]].\n",
      "07/22/2020 02:13:24 PM  [INFO    ]  iteration number 361 is starting\n",
      "07/22/2020 02:13:24 PM  [INFO    ]  Loss : [[427.56109732]].\n",
      "07/22/2020 02:13:26 PM  [INFO    ]  iteration number 381 is starting\n",
      "07/22/2020 02:13:26 PM  [INFO    ]  Loss : [[427.56109938]].\n",
      "07/22/2020 02:13:29 PM  [INFO    ]  iteration number 401 is starting\n",
      "07/22/2020 02:13:29 PM  [INFO    ]  Loss : [[427.56110026]].\n",
      "07/22/2020 02:13:31 PM  [INFO    ]  iteration number 421 is starting\n",
      "07/22/2020 02:13:31 PM  [INFO    ]  Loss : [[427.56110064]].\n",
      "07/22/2020 02:13:34 PM  [INFO    ]  iteration number 441 is starting\n",
      "07/22/2020 02:13:34 PM  [INFO    ]  Loss : [[427.5611008]].\n",
      "07/22/2020 02:13:36 PM  [INFO    ]  iteration number 461 is starting\n",
      "07/22/2020 02:13:36 PM  [INFO    ]  Loss : [[427.56110087]].\n",
      "07/22/2020 02:13:39 PM  [INFO    ]  iteration number 481 is starting\n",
      "07/22/2020 02:13:39 PM  [INFO    ]  Loss : [[427.5611009]].\n",
      "07/22/2020 02:13:41 PM  [INFO    ]  iteration number 501 is starting\n",
      "07/22/2020 02:13:41 PM  [INFO    ]  Loss : [[427.56110091]].\n",
      "07/22/2020 02:13:44 PM  [INFO    ]  iteration number 521 is starting\n",
      "07/22/2020 02:13:44 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:13:46 PM  [INFO    ]  iteration number 541 is starting\n",
      "07/22/2020 02:13:46 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:13:49 PM  [INFO    ]  iteration number 561 is starting\n",
      "07/22/2020 02:13:49 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:13:51 PM  [INFO    ]  iteration number 581 is starting\n",
      "07/22/2020 02:13:51 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:13:54 PM  [INFO    ]  iteration number 601 is starting\n",
      "07/22/2020 02:13:54 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:13:56 PM  [INFO    ]  iteration number 621 is starting\n",
      "07/22/2020 02:13:56 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:13:58 PM  [INFO    ]  iteration number 641 is starting\n",
      "07/22/2020 02:13:58 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:01 PM  [INFO    ]  iteration number 661 is starting\n",
      "07/22/2020 02:14:01 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:04 PM  [INFO    ]  iteration number 681 is starting\n",
      "07/22/2020 02:14:04 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:06 PM  [INFO    ]  iteration number 701 is starting\n",
      "07/22/2020 02:14:06 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:09 PM  [INFO    ]  iteration number 721 is starting\n",
      "07/22/2020 02:14:09 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:11 PM  [INFO    ]  iteration number 741 is starting\n",
      "07/22/2020 02:14:11 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:13 PM  [INFO    ]  iteration number 761 is starting\n",
      "07/22/2020 02:14:13 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:16 PM  [INFO    ]  iteration number 781 is starting\n",
      "07/22/2020 02:14:16 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:19 PM  [INFO    ]  iteration number 801 is starting\n",
      "07/22/2020 02:14:19 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:21 PM  [INFO    ]  iteration number 821 is starting\n",
      "07/22/2020 02:14:21 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:24 PM  [INFO    ]  iteration number 841 is starting\n",
      "07/22/2020 02:14:24 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:26 PM  [INFO    ]  iteration number 861 is starting\n",
      "07/22/2020 02:14:26 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:28 PM  [INFO    ]  iteration number 881 is starting\n",
      "07/22/2020 02:14:28 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:31 PM  [INFO    ]  iteration number 901 is starting\n",
      "07/22/2020 02:14:31 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:33 PM  [INFO    ]  iteration number 921 is starting\n",
      "07/22/2020 02:14:33 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:36 PM  [INFO    ]  iteration number 941 is starting\n",
      "07/22/2020 02:14:36 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:38 PM  [INFO    ]  iteration number 961 is starting\n",
      "07/22/2020 02:14:38 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:41 PM  [INFO    ]  iteration number 981 is starting\n",
      "07/22/2020 02:14:41 PM  [INFO    ]  Loss : [[427.56110092]].\n",
      "07/22/2020 02:14:43 PM  [INFO    ]  Training done. 125.0 seconds\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Training starting\")\n",
    "timer=time.time()\n",
    "unencrypted_model.fit(train_features.to_numpy(), train_labels.to_numpy().reshape((-1, 1)))\n",
    "logging.info(\"Training done. \" + str(round(time.time() - timer, 0)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>...</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>Deck_G</th>\n",
       "      <th>Deck_M</th>\n",
       "      <th>Deck_T</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>0.059965</td>\n",
       "      <td>-0.237248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336238</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-2.048608</td>\n",
       "      <td>2.285767</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336238</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0.285883</td>\n",
       "      <td>-0.459498</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.558133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>0.888333</td>\n",
       "      <td>0.123907</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.599152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>3.072212</td>\n",
       "      <td>-0.440171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.558133</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>-1.069628</td>\n",
       "      <td>-0.210997</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.704781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>-1.144934</td>\n",
       "      <td>0.123907</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.599152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2.243844</td>\n",
       "      <td>-0.502981</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.558133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-0.316566</td>\n",
       "      <td>-0.501773</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.558133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-0.391872</td>\n",
       "      <td>-0.506846</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.558133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age      Fare  Parch  Sex  Family_Size  Pclass_1  Pclass_2  \\\n",
       "726  0.059965 -0.237248      0    0     1.336238         0         1   \n",
       "297 -2.048608  2.285767      2    0     1.336238         1         0   \n",
       "752  0.285883 -0.459498      0    1    -0.558133         0         0   \n",
       "638  0.888333  0.123907      5    0     2.599152         0         0   \n",
       "672  3.072212 -0.440171      0    1    -0.558133         0         1   \n",
       "..        ...       ...    ...  ...          ...       ...       ...   \n",
       "128 -1.069628 -0.210997      1    0     0.704781         0         0   \n",
       "686 -1.144934  0.123907      1    1     2.599152         0         0   \n",
       "94   2.243844 -0.502981      0    1    -0.558133         0         0   \n",
       "154 -0.316566 -0.501773      0    1    -0.558133         0         0   \n",
       "210 -0.391872 -0.506846      0    1    -0.558133         0         0   \n",
       "\n",
       "     Pclass_3  Embarked_C  Embarked_Q  ...  Deck_E  Deck_F  Deck_G  Deck_M  \\\n",
       "726         0           0           0  ...       0       0       0       1   \n",
       "297         0           0           0  ...       0       0       0       0   \n",
       "752         1           0           0  ...       0       0       0       1   \n",
       "638         1           0           0  ...       0       0       0       1   \n",
       "672         0           0           0  ...       0       0       0       1   \n",
       "..        ...         ...         ...  ...     ...     ...     ...     ...   \n",
       "128         1           1           0  ...       0       1       0       0   \n",
       "686         1           0           0  ...       0       0       0       1   \n",
       "94          1           0           0  ...       0       0       0       1   \n",
       "154         1           0           0  ...       0       0       0       1   \n",
       "210         1           0           0  ...       0       0       0       1   \n",
       "\n",
       "     Deck_T  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Rare  \n",
       "726       0             0           0         0          1           0  \n",
       "297       0             0           1         0          0           0  \n",
       "752       0             0           0         1          0           0  \n",
       "638       0             0           0         0          1           0  \n",
       "672       0             0           0         1          0           0  \n",
       "..      ...           ...         ...       ...        ...         ...  \n",
       "128       0             0           1         0          0           0  \n",
       "686       0             0           0         1          0           0  \n",
       "94        0             0           0         1          0           0  \n",
       "154       0             0           0         1          0           0  \n",
       "210       0             0           0         1          0           0  \n",
       "\n",
       "[757 rows x 32 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 02:12:15 PM  [INFO    ]  Accuracy of unencrypted model : 0.582089552238806 \n"
     ]
    }
   ],
   "source": [
    "acc = unencrypted_model.accuracy(test_features.to_numpy(), test_labels.to_numpy().reshape((-1, 1)))\n",
    "logging.info(\"Accuracy of unencrypted model : %s \" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([454.80173529]),\n",
       " array([426.36781425]),\n",
       " array([428.36933328]),\n",
       " array([429.02163776]),\n",
       " array([429.22309978]),\n",
       " array([429.28438469]),\n",
       " array([429.30294403]),\n",
       " array([429.3085569]),\n",
       " array([429.3102537]),\n",
       " array([429.31076659]),\n",
       " array([429.31092161]),\n",
       " array([429.31096847]),\n",
       " array([429.31098263]),\n",
       " array([429.31098691]),\n",
       " array([429.31098821]),\n",
       " array([429.3109886]),\n",
       " array([429.31098872]),\n",
       " array([429.31098875]),\n",
       " array([429.31098876]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877]),\n",
       " array([429.31098877])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unencrypted_model.true_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unencrypted_model.weight.dot(unencrypted_model.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encrypted and unencrypted losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i*VERBOSE for i in range(len(model.loss_list))], [i.decrypt()[0] for i in model.loss_list], label='cipherloss')\n",
    "plt.plot([i*VERBOSE for i in range(len(unencrypted_model.loss_list))], unencrypted_model.loss_list, label='plainloss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Losses evolution of both models')\n",
    "plt.legend(loc='best')\n",
    "[i.decrypt()[0] for i in model.loss_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unencrypted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss evolution of unencrypted model')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 02:06:27 PM  [DEBUG   ]  update_title_pos\n",
      "07/22/2020 02:06:27 PM  [DEBUG   ]  findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/home/apignet/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n",
      "07/22/2020 02:06:27 PM  [DEBUG   ]  update_title_pos\n",
      "07/22/2020 02:06:27 PM  [DEBUG   ]  update_title_pos\n",
      "07/22/2020 02:06:27 PM  [DEBUG   ]  update_title_pos\n",
      "07/22/2020 02:06:27 PM  [DEBUG   ]  update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i*VERBOSE for i in range(len(unencrypted_model.loss_list))], np.array(unencrypted_model.loss_list).reshape((-1)))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss evolution of unencrypted model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logging.info(\"Model initialization\")\n",
    "unencrypted_model = unencrypted_LR.LogisticRegression(init_weight=unencrypted_weight,\n",
    "                                                      init_bias=unencrypted_bias,\n",
    "                                                      verbose=VERBOSE,\n",
    "                                                      save_weight= SAVE_WEIGHT,\n",
    "                                                      max_epoch==EPOCH,\n",
    "                                                      lr=LEARNING_RATE,\n",
    "                                                      reg_para=REGULARIZATION_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative error between losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypted = [i.decrypt()[0] for i in model.loss_list]\n",
    "true_err = np.abs(np.array(decrypted) - np.array(unencrypted_model.loss_list))\n",
    "rel_err = true_err/np.linalg.norm(decrypted)\n",
    "rel_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot([i*VERBOSE for i in range(len(model.loss_list))],  rel_err)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Relative error on loss')\n",
    "plt.title('Relative error between encrypted loss and unencrypted loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative error between weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = encryption_error(model.weight_list,model.bias_list, unencrypted_model.weight_list,unencrypted_model.bias_list)\n",
    "plt.plot([i*VERBOSE for i in range(len(error_list))], error_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Relative error on weights')\n",
    "plt.title('Relative error between encrypted weights and unencrypted weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
