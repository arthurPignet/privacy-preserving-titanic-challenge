{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import tenseal as ts\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.chdir(\"C://Users//apignet//Documents/homomorphic-encryption/ckks_titanic/\")\n",
    "from src.features import build_features\n",
    "from models import encrypted_LR\n",
    "from models import unencrypted_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# definition of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileHandler = logging.FileHandler(\"{0}/{1}.log\".format(LOG_PATH, LOG_FILENAME))\n",
    "streamHandler = logging.StreamHandler(sys.stdout)\n",
    "logging.basicConfig(format=\"%(asctime)s  [%(levelname)-8.8s]  %(message)s\", datefmt='%m/%d/%Y %I:%M:%S %p', level = logging.INFO, handlers=[fileHandler, streamHandler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/data/raw/\"            # whole data set\n",
    "#DATA_PATH = \"/data/quick_demo/\"   # subset of the data set, with 15 train_samples and 5 test_samples\n",
    "#DATA_PATH = \"/home/apignet/homomorphic-encryption/ckks_titanic/data/quick_demo/\"   # subset of the data set, with 400 train_samples and 50 test_samples\n",
    "#DATA_PATH =   '/data/quick_demo/'\n",
    "LOG_PATH = \"reports/log\"\n",
    "LOG_FILENAME = \"test_0716\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\apignet\\\\Documents\\\\homomorphic-encryption\\\\ckks_titanic'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 40\n",
    "LEARNING_RATE = 0.9\n",
    "MOMENTUM_RATE = 0.6\n",
    "REGULARIZATION_RATE = 0.5\n",
    "VERBOSE = 2\n",
    "SAVE_WEIGHT = 2\n",
    "N_JOBS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crytp_array(X, local_context):\n",
    "    \"\"\"\n",
    "    This function encrypt a list of vector\n",
    "    \n",
    "    :parameters \n",
    "    ------------\n",
    "    \n",
    "    :param X ; list of list, interpreted as list of vector to encrypt\n",
    "    :param local_context ; TenSEAL context object used to encrypt\n",
    "    \n",
    "    :returns\n",
    "    ------------\n",
    "    \n",
    "    list ; list of CKKS ciphertext  \n",
    "    \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(len(X)):\n",
    "        res.append(ts.ckks_vector(local_context, X[i]))\n",
    "        if i == len(X) // 4:\n",
    "            logging.info(\"25 % ...\")\n",
    "        elif i == len(X) // 2 :\n",
    "            logging.info(\"50 % ...\")\n",
    "        elif i == 3* len(X)//4:\n",
    "            logging.info(\"75% ...\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidential functions\n",
    "\n",
    "These functions involves security breachs (as use of unencrypted data, or decryption of weights) and cannot be coded by Alice.\n",
    "However, the functions encapslulate the unsafe process, so can be performed by Alice if Bob provides them. \n",
    "Therefore, they are currently passed as parameters to Alice, which only calls them.\n",
    "\n",
    "Currently there is a huge security breach, as confidential parameters (security key for instance), which are needed by those functions, are passed in a dictionnary to Alice. \n",
    "For a safe protocole, we have to change these functions, to set up a safe communication protocole between Bob and Alice.\n",
    "Alice will therefore only send the crypted data to Bob (using these functions, in which can be set up the communication process) and Bob will locally perform the functions which are currently coded bellow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh(ciphertext, **kwarg):\n",
    "    \"\"\"\n",
    "    This function is here to refresh a ciphertext. This operation reset to 0 the calculus depth of the input ciphertext \n",
    "    WARNING :  Basically the function decryt and re-encrypt the ciphertext. \n",
    "    This is not safe, this operation needs to be done by a trusted part \n",
    "    (Bob for the perfect instance, even if it requieres communications between Alice and Bob while training)\n",
    "    \n",
    "    :parameters \n",
    "    ------------\n",
    "    \n",
    "    ciphertext ; encrypted CKKS vector \n",
    "    **kwarg ; dict, must contain context and secret_key.\n",
    "    \n",
    "    :returns\n",
    "    ------------\n",
    "    \n",
    "    ciphertext : encrypted CKKS vector \n",
    "    \n",
    "    \"\"\"\n",
    "    context = kwarg.get(\"context\", None)\n",
    "    secret_key = kwarg.get(\"secret_key\", None)\n",
    "    assert context , \"Context must be provided with the key : context\"+str(context)\n",
    "    if context.is_private():\n",
    "        return ts.ckks_vector(context, ciphertext.decrypt())\n",
    "    else : \n",
    "        if not secret_key:\n",
    "            raise AttributeError(\"The secret key is not provided and the context provided is public, decryption is not possible\")\n",
    "        else:\n",
    "            return ts.ckks_vector(context, ciphertext.decrypt(secret_key))\n",
    "   \n",
    "            \n",
    "def accuracy(crypted_weight, crypted_bias, prior_unencrypted_X = None, prior_unencrypted_Y=None, **kwarg):\n",
    "    \"\"\"\n",
    "    This function is here to compute the accuracy\n",
    "    1-NOTE : we could maybe estimate this function homomorphically, by designing an approximation of the sign function. \n",
    "    However, this kind of approximation seems really hard to set up \n",
    "    Therefore, we will not be able to use the metric, as the result is encrypted.\n",
    "    2-NOTE : this function could be parallelized, as we do not need the result for the next epoch. \n",
    "    \n",
    "    :parameters \n",
    "    ------------\n",
    "    \n",
    "    crypted_weight ; encrypted CKKS vector (size equal to the number of features)\n",
    "    crypted_bias ; encrypted CKKS vector (size 1)\n",
    "    (Optionnal) prior_unencrypted_X ; samples on which the model accuracy will be computed. \n",
    "                                If not provided, the accuracy will be computed with the data provided in the kwarg\n",
    "    (Optionnal) prior_unencrypted_Y ; labels on which the model accuracy will be computed. If not provided.\n",
    "                                If not provided, the accuracy will be computed with the data provided in the kwarg\n",
    "    **kwarg ; dict, must contain context, secret_key, (Optionnal) unencrytped_X and (Optionnal) unencrypted_Y \n",
    "    \n",
    "    :returns\n",
    "    ------------\n",
    "    \n",
    "    accuray : float (rounded to 2 digits)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    context = kwarg.get(\"context\", None)\n",
    "    if not context:\n",
    "        raise AttributeError(\"Context must be provided in the **kwarg, with the key : context\")\n",
    "    secret_key = kwarg.get(\"secret_key\", None)\n",
    "    if prior_unencrypted_X is None:\n",
    "        unencrypted_X = kwarg.get(\"unencrypted_X\", None)\n",
    "        if unencrypted_X is None:\n",
    "            raise AttributeError(\"Unencrypted samples must be provided, either in the arguments, or in the **kwarg, with the key : unencrypted_X\")\n",
    "    else:\n",
    "        unencrypted_X = np.array(prior_unencrypted_X)\n",
    "    if prior_unencrypted_Y is None:\n",
    "        unencrypted_Y = kwarg.get(\"unencrypted_Y\", None)\n",
    "        if unencrypted_Y is None:\n",
    "            raise AttributeError(\"Unencrypted labels must be provided, either in the arguments, or in the **kwarg, with the key : unencrypted_Y\")\n",
    "    else:\n",
    "        unencrypted_Y = np.array(prior_unencrypted_Y)\n",
    "    if context.is_private():\n",
    "            weight = np.array(crypted_weight.decrypt())\n",
    "            bias = np.array(crypted_bias.decrypt())\n",
    "    else : \n",
    "        if not secret_key:\n",
    "            raise AttributeError(\"The secret key is not provided and the context provided is public, decryption is not possible. Pass a private context or the secret key\")\n",
    "        else:\n",
    "            weight = np.array(crypted_weight.decrypt(secret_key))\n",
    "            bias = np.array(crypted_bias.decrypt(secret_key))\n",
    "            \n",
    "    re = unencrypted_X.dot(weight) + bias  \n",
    "    prediction = (np.float_power(re, 3)) * -0.004 + re * 0.197 + 0.5\n",
    "    print(prediction)\n",
    "    return (np.abs((unencrypted_Y-prediction.reshape(unencrypted_Y.shape))) < 0.5).astype(float).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27/2020 03:26:20 PM  [INFO    ]  C:\\Users\\apignet\\Documents\\homomorphic-encryption\\ckks_titanic\n",
      "07/27/2020 03:26:20 PM  [INFO    ]  loading the data into memory (pandas df)\n",
      "07/27/2020 03:26:20 PM  [INFO    ]  Done\n",
      "07/27/2020 03:26:20 PM  [INFO    ]  making final data set from raw data\n",
      "07/27/2020 03:26:20 PM  [INFO    ]  Done\n",
      "07/27/2020 03:26:21 PM  [INFO    ]  C:\\Users\\apignet\\Documents\\homomorphic-encryption\\ckks_titanic\n",
      "07/27/2020 03:26:21 PM  [INFO    ]  loading the data into memory (pandas df)\n",
      "07/27/2020 03:26:21 PM  [INFO    ]  Done\n",
      "07/27/2020 03:26:21 PM  [INFO    ]  making final data set from raw data\n",
      "07/27/2020 03:26:21 PM  [INFO    ]  Done\n",
      "peak memory: 133.14 MiB, increment: 3.11 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "logging.info(os.getcwd())\n",
    "raw_train, raw_test = build_features.data_import(os.getcwd()+DATA_PATH)\n",
    "train, submission_test = build_features.processing(raw_train, raw_test)\n",
    "del submission_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 132.84 MiB, increment: 0.02 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "train, test = train_test_split(train, test_size=0.15)\n",
    "train_labels = train.Survived\n",
    "test_labels = test.Survived\n",
    "train_features = train.drop(\"Survived\", axis=1)\n",
    "test_features = test.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of safety parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27/2020 03:26:25 PM  [INFO    ]  Definition of safety parameters...\n",
      "07/27/2020 03:26:27 PM  [INFO    ]  Done. 2.05 seconds\n",
      "07/27/2020 03:26:27 PM  [INFO    ]  Generation of the secret key...\n",
      "07/27/2020 03:26:27 PM  [INFO    ]  Done. 0.0 seconds\n",
      "07/27/2020 03:26:27 PM  [INFO    ]  Generation of the Galois Key...\n",
      "07/27/2020 03:26:35 PM  [INFO    ]  Done. 7.32 seconds\n",
      "07/27/2020 03:26:35 PM  [INFO    ]  Generation of the Relin Key...\n",
      "07/27/2020 03:26:35 PM  [INFO    ]  Done. 0.26 seconds\n",
      "peak memory: 703.13 MiB, increment: 570.31 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "logging.info('Definition of safety parameters...')\n",
    "timer = time.time()\n",
    "# context = ts.context(ts.SCHEME_TYPE.CKKS, 32768,\n",
    "# coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 60])\n",
    "#context = ts.context(ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[40, 21, 21, 21, 21, 21, 21, 40])\n",
    "\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, 16384, coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 40, 40,40, 60])\n",
    "context.global_scale = pow(2, 40)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "\n",
    "\n",
    "logging.info('Generation of the secret key...')\n",
    "timer = time.time()\n",
    "secret_key = context.secret_key()\n",
    "#context.make_context_public() #drop the relin keys, the galois keys, and the secret keys. \n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "logging.info('Generation of the Galois Key...')\n",
    "timer = time.time()\n",
    "context.generate_galois_keys(secret_key)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "logging.info('Generation of the Relin Key...')\n",
    "timer = time.time()\n",
    "context.generate_relin_keys(secret_key)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "if context.is_public():\n",
    "    logging.info(\"The context is now public, the context do not hold the secret key anymore, and decrypt methods need the secret key to be provide,\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27/2020 03:26:37 PM  [INFO    ]  Data encryption...\n",
      "07/27/2020 03:26:37 PM  [INFO    ]  25 % ...\n",
      "07/27/2020 03:26:37 PM  [INFO    ]  50 % ...\n",
      "07/27/2020 03:26:37 PM  [INFO    ]  75% ...\n",
      "07/27/2020 03:26:37 PM  [INFO    ]  25 % ...\n",
      "07/27/2020 03:26:37 PM  [INFO    ]  50 % ...\n",
      "07/27/2020 03:26:37 PM  [INFO    ]  75% ...\n",
      "07/27/2020 03:26:37 PM  [INFO    ]  25 % ...\n",
      "07/27/2020 03:26:37 PM  [INFO    ]  50 % ...\n",
      "07/27/2020 03:26:38 PM  [INFO    ]  25 % ...\n",
      "07/27/2020 03:26:38 PM  [INFO    ]  50 % ...\n",
      "07/27/2020 03:26:38 PM  [INFO    ]  Done. 0.94 seconds\n",
      "peak memory: 743.68 MiB, increment: 42.88 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "logging.info(\"Data encryption...\")\n",
    "timer = time.time()\n",
    "encrypted_X = crytp_array(train_features.to_numpy(), context)\n",
    "encrypted_Y = crytp_array(train_labels.to_numpy().reshape((-1, 1)), context)\n",
    "encrypted_test_X = crytp_array(test_features.to_numpy(), context)\n",
    "encrypted_test_Y = crytp_array(test_labels.to_numpy().reshape((-1, 1)), context)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the weight\n",
    "\n",
    "The weights have to be crypted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27/2020 03:26:39 PM  [INFO    ]  [-0.22499071  0.0217117   0.21590355 -0.05652833  0.0316512   0.18683547\n",
      " -0.1044495   0.21870333  0.10480822 -0.23649985 -0.05403479 -0.52222564\n",
      "  0.16411125  0.02371336  0.2223994  -0.04740946 -0.10065089 -0.07294417\n",
      "  0.1094202   0.22376479 -0.13496316 -0.37084304 -0.16429159  0.0094881\n",
      " -0.05522279  0.12370205 -0.23874948  0.18194361 -0.11727004 -0.28277741\n",
      "  0.1220219 ]\n",
      "07/27/2020 03:26:40 PM  [INFO    ]  [-0.05183263  0.12221946 -0.167971   -0.18320169  0.20807161  0.02890496\n",
      "  0.06963413  0.14879086  0.00594222 -0.28962672  0.10918458 -0.25631794\n",
      " -0.08756078 -0.08985175 -0.05430238  0.11189951 -0.4760695   0.00977977\n",
      " -0.06056058  0.35275715 -0.20244354  0.05195408 -0.20391283  0.37559874\n",
      " -0.32736981 -0.10821837  0.04168602 -0.18298197  0.05716393 -0.07911535\n",
      " -0.04329306]\n",
      "peak memory: 749.82 MiB, increment: 7.26 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "unencrypted_weight = np.random.normal(loc=0,\n",
    "                                      scale=0.2, size =(train_features.to_numpy().shape[1]))\n",
    "logging.info(unencrypted_weight)\n",
    "weight = ts.ckks_vector(context, unencrypted_weight)\n",
    "unencrypted_weight = np.array(unencrypted_weight)\n",
    "unencrypted_bias = np.random.random((1))\n",
    "bias = ts.ckks_vector(context, unencrypted_bias)\n",
    "unencrypted_bias = np.array(unencrypted_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidential data as yet stored into a dictionnary, and will be used during the training only by functions which are passed as arguments to the fit methods. This encapsulation of sensitive data will allows us to ensure security during training later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 748.73 MiB, increment: 0.04 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "confidential_data = {'context':context,\n",
    "                     'secret_key':secret_key, \n",
    "                     'unencrypted_X':train_features.to_numpy(),\n",
    "                     'unencrypted_Y':train_labels.to_numpy().reshape((-1, 1)) \n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the unencrypted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27/2020 03:26:45 PM  [INFO    ]  Model initialization\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Model initialization\")\n",
    "unencrypted_model = unencrypted_LR.LogisticRegression(init_weight=unencrypted_weight,\n",
    "                                                      init_bias=unencrypted_bias,\n",
    "                                                      verbose=VERBOSE,\n",
    "                                                      save_weight= SAVE_WEIGHT,\n",
    "                                                      max_epoch=EPOCH,\n",
    "                                                      learning_rate=LEARNING_RATE,\n",
    "                                                      momentum_rate=MOMENTUM_RATE,\n",
    "                                                      reg_para=REGULARIZATION_RATE,\n",
    "                                                      n_jobs = N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27/2020 03:26:45 PM  [INFO    ]  Training starting\n",
      "07/27/2020 03:26:45 PM  [INFO    ]  Just finished iteration number 1. Starting computations of the loss \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'resahpe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-844975b44da7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training starting\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0munencrypted_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training done. \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" seconds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\homomorphic-encryption\\ckks_titanic\\models\\unencrypted_LR.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_loss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weight\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weight\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\homomorphic-encryption\\ckks_titanic\\models\\unencrypted_LR.py\u001b[0m in \u001b[0;36mtrue_loss\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreg_para\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat_power\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresahpe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'resahpe'"
     ]
    }
   ],
   "source": [
    "logging.info(\"Training starting\")\n",
    "timer=time.time()\n",
    "unencrypted_model.fit(train_features.to_numpy(), train_labels.to_numpy().reshape((-1, 1)))\n",
    "logging.info(\"Training done. \" + str(round(time.time() - timer, 0)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unencrypted accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = unencrypted_model.accuracy(test_features.to_numpy(), test_labels.to_numpy().reshape((-1, 1)))\n",
    "logging.info(\"Accuracy of unencrypted model : %s \" % acc)\n",
    "\n",
    "plt.plot([i*VERBOSE for i in range(len(unencrypted_model.loss_list))], unencrypted_model.loss_list,'-xr' ,label='plainloss')\n",
    "plt.plot([i*VERBOSE for i in range(len(unencrypted_model.true_loss_list))], unencrypted_model.true_loss_list, '-ob', label='True plainloss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Losses evolution of unencrypted model with momentum')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the crypted models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Model initialization\")\n",
    "model = encrypted_LR.LogisticRegressionHE(init_weight=weight,\n",
    "                                          init_bias=bias,\n",
    "                                          refresh_function=refresh, \n",
    "                                          confidential_kwarg=confidential_data,\n",
    "                                          accuracy=accuracy,\n",
    "                                          verbose=VERBOSE,\n",
    "                                          save_weight=SAVE_WEIGHT,\n",
    "                                          max_epoch=EPOCH,\n",
    "                                          learning_rate=LEARNING_RATE,\n",
    "                                          momentum_rate=MOMENTUM_RATE,\n",
    "                                          reg_para=REGULARIZATION_RATE,\n",
    "                                          n_jobs = N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Training starting\")\n",
    "timer=time.time()\n",
    "model.fit(encrypted_X, encrypted_Y)\n",
    "logging.info(\"Training done. \" + str(round(time.time() - timer, 0)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encrypted and unencrypted losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i*VERBOSE for i in range(len(model.loss_list))], [i.decrypt(secret_key)[0] for i in model.loss_list],'-or', label='cipherloss')\n",
    "\n",
    "plt.plot([i*VERBOSE for i in range(len(unencrypted_model.loss_list))], unencrypted_model.loss_list, label='plainloss')\n",
    "plt.plot([i*VERBOSE for i in range(len(unencrypted_model.true_loss_list))], unencrypted_model.true_loss_list, label='True plainloss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Losses evolution of both models')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unencrypted loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative error between losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypted = [i.decrypt(secret_key)[0] for i in model.loss_list]\n",
    "true_err_cl = np.abs(np.array(decrypted) - np.array(unencrypted_model.loss_list))\n",
    "rel_err_cl = true_err_cl/np.abs(decrypted)\n",
    "true_err_ct = np.abs(np.array(decrypted) - np.array(unencrypted_model.true_loss_list))\n",
    "rel_err_ct = true_err_ct/np.abs(decrypted)\n",
    "true_err_lt = np.abs(np.array(unencrypted_model.loss_list) - np.array(unencrypted_model.true_loss_list))\n",
    "rel_err_lt = true_err_lt/np.abs(unencrypted_model.true_loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i*VERBOSE for i in range(len(model.loss_list))],  rel_err_cl, label='cipherloss and plainloss')\n",
    "plt.plot([i*VERBOSE for i in range(len(model.loss_list))],  rel_err_ct, label='cipherloss and trueloss' )\n",
    "plt.plot([i*VERBOSE for i in range(len(model.loss_list))],  rel_err_lt, label='plainlosses')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Relative error on loss')\n",
    "plt.title('Relative error between losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative error between weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwl = np.array([i.decrypt(secret_key) for i in model.weight_list])\n",
    "dbl = np.array([i.decrypt(secret_key) for i in model.bias_list]).reshape((-1,1))\n",
    "dl = np.concatenate((dwl,dbl), axis=1)\n",
    "\n",
    "ul = np.concatenate((np.array(unencrypted_model.weight_list), np.array(unencrypted_model.bias_list).reshape((-1,1))), axis=1)\n",
    "wm_err = np.mean((np.abs(dl-ul)/np.abs(ul)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwl = np.array([i.decrypt(secret_key) for i in model_nm.weight_list])\n",
    "dbl = np.array([i.decrypt(secret_key) for i in model_nm.bias_list]).reshape((-1,1))\n",
    "dl = np.concatenate((dwl,dbl), axis=1)\n",
    "\n",
    "d2wl = np.array([i.decrypt(secret_key) for i in model.weight_list])\n",
    "d2bl = np.array([i.decrypt(secret_key) for i in model.bias_list]).reshape((-1,1))\n",
    "d2l = np.concatenate((d2wl,d2bl), axis=1)\n",
    "\n",
    "w2_err = np.mean((np.abs(dl-d2l)/np.abs(dl)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot([i*VERBOSE for i in range(w_err.shape[0])],wm_err)\n",
    "plt.plot([i*VERBOSE for i in range(w_err.shape[0])],w_err)\n",
    "#plt.plot([i*VERBOSE for i in range(w_err.shape[0])],w2_err)\n",
    "\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Relative error on weights')\n",
    "plt.title('Relative error between encrypted weights and unencrypted weights')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TenSEAL",
   "language": "python",
   "name": "tenseal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
