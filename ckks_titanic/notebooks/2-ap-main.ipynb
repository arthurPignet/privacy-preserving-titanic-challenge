{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import tenseal as ts\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.chdir(\"..\")\n",
    "from src.features import build_features\n",
    "from models import encrypted_LR\n",
    "from models import unencrypted_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# definition of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = \"\\\\data\\\\raw\\\\\"            # whole data set\n",
    "DATA_PATH = \"/data/quick_demo/\"   # subset of the data set, with 15 train_samples and 5 test_samples\n",
    "#DATA_PATH = \"/home/apignet/homomorphic-encryption/ckks_titanic/data/quick_demo/\"   # subset of the data set, with 400 train_samples and 50 test_samples\n",
    "LOG_PATH = \"reports/log\"\n",
    "LOG_FILENAME = \"test_0716\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\apignet\\\\Documents\\\\homomorphic-encryption\\\\ckks_titanic'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileHandler = logging.FileHandler(\"{0}/{1}.log\".format(LOG_PATH, LOG_FILENAME))\n",
    "streamHandler = logging.StreamHandler(sys.stdout)\n",
    "logging.basicConfig(format=\"%(asctime)s  [%(levelname)-8.8s]  %(message)s\", datefmt='%m/%d/%Y %I:%M:%S %p', level = logging.DEBUG, handlers=[fileHandler, streamHandler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 20\n",
    "LEARNING_RATE = 0.8\n",
    "REGULARIZATION_RATE = 0.5\n",
    "VERBOSE = 2\n",
    "SAVE_WEIGHT = 2\n",
    "N_JOBS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crytp_array(X, local_context):\n",
    "    \"\"\"\n",
    "    This function encrypt a list of vector\n",
    "    \n",
    "    :parameters \n",
    "    ------------\n",
    "    \n",
    "    :param X ; list of list, interpreted as list of vector to encrypt\n",
    "    :param local_context ; TenSEAL context object used to encrypt\n",
    "    \n",
    "    :returns\n",
    "    ------------\n",
    "    \n",
    "    list ; list of CKKS ciphertext  \n",
    "    \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(len(X)):\n",
    "        res.append(ts.ckks_vector(local_context, X[i]))\n",
    "        if i == len(X) // 4:\n",
    "            logging.info(\"25 % ...\")\n",
    "        elif i == len(X) // 2 :\n",
    "            logging.info(\"50 % ...\")\n",
    "        elif i == 3* len(X)//4:\n",
    "            logging.info(\"75% ...\")\n",
    "    return res\n",
    "\n",
    "def encryption_error(encrypted_weight,encrypted_bias, unencrypted_weight, unencrypted_bias, secret_key=None):\n",
    "    \n",
    "    def err(encrypted_weight,encrypted_bias, unencrypted_weight, unencrypted_bias, secret_key=secret_key):\n",
    "        if secret_key is None:\n",
    "            return (np.sum(np.power((np.array(encrypted_weight.decrypt()) - unencrypted_weight), 2)) + np.power((np.array(encrypted_bias.decrypt()) - unencrypted_bias), 2)) / (np.sum(np.power(unencrypted_weight, 2)) + np.power(unencrypted_bias,2))\n",
    "        else:\n",
    "            return (np.sum(np.power((np.array(encrypted_weight.decrypt(secret_key)) - unencrypted_weight), 2)) + np.power((np.array(encrypted_bias.decrypt(secret_key)) - unencrypted_bias), 2)) / (np.sum(np.power(unencrypted_weight, 2)) + np.power(unencrypted_bias,2))\n",
    "    \n",
    "    \n",
    "    res = [0 for _ in range(len(encrypted_bias))]\n",
    "    for i in range(len(encrypted_bias)):\n",
    "        res[i]=err(encrypted_weight[i], encrypted_bias[i],unencrypted_weight[i], unencrypted_bias[i], secret_key=secret_key)\n",
    "        \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidential functions\n",
    "\n",
    "These functions involves security breachs (as use of unencrypted data, or decryption of weights) and cannot be coded by Alice.\n",
    "However, the functions encapslulate the unsafe process, so can be performed by Alice if Bob provides them. \n",
    "Therefore, they are currently passed as parameters to Alice, which only calls them.\n",
    "\n",
    "Currently there is a huge security breach, as confidential parameters (security key for instance), which are needed by those functions, are passed in a dictionnary to Alice. \n",
    "For a safe protocole, we have to change these functions, to set up a safe communication protocole between Bob and Alice.\n",
    "Alice will therefore only send the crypted data to Bob (using these functions, in which can be set up the communication process) and Bob will locally perform the functions which are currently coded bellow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh(ciphertext, **kwarg):\n",
    "    \"\"\"\n",
    "    This function is here to refresh a ciphertext. This operation reset to 0 the calculus depth of the input ciphertext \n",
    "    WARNING :  Basically the function decryt and re-encrypt the ciphertext. \n",
    "    This is not safe, this operation needs to be done by a trusted part \n",
    "    (Bob for the perfect instance, even if it requieres communications between Alice and Bob while training)\n",
    "    \n",
    "    :parameters \n",
    "    ------------\n",
    "    \n",
    "    ciphertext ; encrypted CKKS vector \n",
    "    **kwarg ; dict, must contain context and secret_key.\n",
    "    \n",
    "    :returns\n",
    "    ------------\n",
    "    \n",
    "    ciphertext : encrypted CKKS vector \n",
    "    \n",
    "    \"\"\"\n",
    "    context = kwarg.get(\"context\", None)\n",
    "    secret_key = kwarg.get(\"secret_key\", None)\n",
    "    assert context , \"Context must be provided with the key : context\"+str(context)\n",
    "    if context.is_private():\n",
    "        return ts.ckks_vector(context, ciphertext.decrypt())\n",
    "    else : \n",
    "        if not secret_key:\n",
    "            raise AttributeError(\"The secret key is not provided and the context provided is public, decryption is not possible\")\n",
    "        else:\n",
    "            return ts.ckks_vector(context, ciphertext.decrypt(secret_key))\n",
    "   \n",
    "            \n",
    "def accuracy(crypted_weight, crypted_bias, prior_unencrypted_X = None, prior_unencrypted_Y=None, **kwarg):\n",
    "    \"\"\"\n",
    "    This function is here to compute the accuracy\n",
    "    1-NOTE : we could maybe estimate this function homomorphically, by designing an approximation of the sign function. \n",
    "    However, this kind of approximation seems really hard to set up \n",
    "    Therefore, we will not be able to use the metric, as the result is encrypted.\n",
    "    2-NOTE : this function could be parallelized, as we do not need the result for the next epoch. \n",
    "    \n",
    "    :parameters \n",
    "    ------------\n",
    "    \n",
    "    crypted_weight ; encrypted CKKS vector (size equal to the number of features)\n",
    "    crypted_bias ; encrypted CKKS vector (size 1)\n",
    "    (Optionnal) prior_unencrypted_X ; samples on which the model accuracy will be computed. \n",
    "                                If not provided, the accuracy will be computed with the data provided in the kwarg\n",
    "    (Optionnal) prior_unencrypted_Y ; labels on which the model accuracy will be computed. If not provided.\n",
    "                                If not provided, the accuracy will be computed with the data provided in the kwarg\n",
    "    **kwarg ; dict, must contain context, secret_key, (Optionnal) unencrytped_X and (Optionnal) unencrypted_Y \n",
    "    \n",
    "    :returns\n",
    "    ------------\n",
    "    \n",
    "    accuray : float (rounded to 2 digits)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    context = kwarg.get(\"context\", None)\n",
    "    if not context:\n",
    "        raise AttributeError(\"Context must be provided in the **kwarg, with the key : context\")\n",
    "    secret_key = kwarg.get(\"secret_key\", None)\n",
    "    if prior_unencrypted_X is None:\n",
    "        unencrypted_X = kwarg.get(\"unencrypted_X\", None)\n",
    "        if unencrypted_X is None:\n",
    "            raise AttributeError(\"Unencrypted samples must be provided, either in the arguments, or in the **kwarg, with the key : unencrypted_X\")\n",
    "    else:\n",
    "        unencrypted_X = np.array(prior_unencrypted_X)\n",
    "    if prior_unencrypted_Y is None:\n",
    "        unencrypted_Y = kwarg.get(\"unencrypted_Y\", None)\n",
    "        if unencrypted_Y is None:\n",
    "            raise AttributeError(\"Unencrypted labels must be provided, either in the arguments, or in the **kwarg, with the key : unencrypted_Y\")\n",
    "    else:\n",
    "        unencrypted_Y = np.array(prior_unencrypted_Y)\n",
    "    if context.is_private():\n",
    "            weight = np.array(crypted_weight.decrypt())\n",
    "            bias = np.array(crypted_bias.decrypt())\n",
    "    else : \n",
    "        if not secret_key:\n",
    "            raise AttributeError(\"The secret key is not provided and the context provided is public, decryption is not possible. Pass a private context or the secret key\")\n",
    "        else:\n",
    "            weight = np.array(crypted_weight.decrypt(secret_key))\n",
    "            bias = np.array(crypted_bias.decrypt(secret_key))\n",
    "            \n",
    "    re = unencrypted_X.dot(weight) + bias  \n",
    "    prediction = (np.float_power(re, 3)) * -0.004 + re * 0.197 + 0.5\n",
    "    print(prediction)\n",
    "    return (np.abs((unencrypted_Y-prediction.reshape(unencrypted_Y.shape))) < 0.5).astype(float).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 05:58:14 PM  [INFO    ]  C:\\Users\\apignet\\Documents\\homomorphic-encryption\\ckks_titanic\n",
      "07/22/2020 05:58:14 PM  [INFO    ]  loading the data into memory (pandas df)\n",
      "07/22/2020 05:58:14 PM  [INFO    ]  Done\n",
      "07/22/2020 05:58:14 PM  [INFO    ]  making final data set from raw data\n",
      "07/22/2020 05:58:14 PM  [INFO    ]  Done\n",
      "07/22/2020 05:58:15 PM  [INFO    ]  C:\\Users\\apignet\\Documents\\homomorphic-encryption\\ckks_titanic\n",
      "07/22/2020 05:58:15 PM  [INFO    ]  loading the data into memory (pandas df)\n",
      "07/22/2020 05:58:15 PM  [INFO    ]  Done\n",
      "07/22/2020 05:58:15 PM  [INFO    ]  making final data set from raw data\n",
      "07/22/2020 05:58:15 PM  [INFO    ]  Done\n",
      "peak memory: 133.28 MiB, increment: 3.27 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "logging.info(os.getcwd())\n",
    "raw_train, raw_test = build_features.data_import(os.getcwd()+DATA_PATH)\n",
    "train, submission_test = build_features.processing(raw_train, raw_test)\n",
    "del submission_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 133.04 MiB, increment: 0.02 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "train, test = train_test_split(train, test_size=0.15)\n",
    "train_labels = train.Survived\n",
    "test_labels = test.Survived\n",
    "train_features = train.drop(\"Survived\", axis=1)\n",
    "test_features = test.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of safety parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 05:58:20 PM  [INFO    ]  Definition of safety parameters...\n",
      "07/22/2020 05:58:22 PM  [INFO    ]  Done. 2.04 seconds\n",
      "07/22/2020 05:58:22 PM  [INFO    ]  Generation of the Galois Key...\n",
      "07/22/2020 05:58:28 PM  [INFO    ]  Done. 6.01 seconds\n",
      "peak memory: 687.32 MiB, increment: 554.28 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "logging.info('Definition of safety parameters...')\n",
    "timer = time.time()\n",
    "# context = ts.context(ts.SCHEME_TYPE.CKKS, 32768,\n",
    "# coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 60])\n",
    "#context = ts.context(ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[40, 21, 21, 21, 21, 21, 21, 40])\n",
    "\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, 16384, coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 40, 40, 40, 60])\n",
    "context.global_scale = pow(2, 40)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "logging.info('Generation of the Galois Key...')\n",
    "timer = time.time()\n",
    "context.generate_galois_keys()\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "\n",
    "#logging.info('Generation of the secret key...')\n",
    "#timer = time.time()\n",
    "secret_key = context.secret_key()\n",
    "#context.make_context_public()\n",
    "#logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "#if context.is_public():\n",
    "#    logging.info(\"The context is now public, the context do not hold the secret key anymore, and decrypt methods need the secret key to be provide,\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 05:58:29 PM  [INFO    ]  Data encryption...\n",
      "07/22/2020 05:58:29 PM  [INFO    ]  25 % ...\n",
      "07/22/2020 05:58:29 PM  [INFO    ]  50 % ...\n",
      "07/22/2020 05:58:29 PM  [INFO    ]  75% ...\n",
      "07/22/2020 05:58:29 PM  [INFO    ]  25 % ...\n",
      "07/22/2020 05:58:30 PM  [INFO    ]  50 % ...\n",
      "07/22/2020 05:58:30 PM  [INFO    ]  75% ...\n",
      "07/22/2020 05:58:30 PM  [INFO    ]  25 % ...\n",
      "07/22/2020 05:58:30 PM  [INFO    ]  50 % ...\n",
      "07/22/2020 05:58:30 PM  [INFO    ]  25 % ...\n",
      "07/22/2020 05:58:30 PM  [INFO    ]  50 % ...\n",
      "07/22/2020 05:58:30 PM  [INFO    ]  Done. 0.89 seconds\n",
      "peak memory: 727.06 MiB, increment: 44.25 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "logging.info(\"Data encryption...\")\n",
    "timer = time.time()\n",
    "encrypted_X = crytp_array(train_features.to_numpy(), context)\n",
    "encrypted_Y = crytp_array(train_labels.to_numpy().reshape((-1, 1)), context)\n",
    "encrypted_test_X = crytp_array(test_features.to_numpy(), context)\n",
    "encrypted_test_Y = crytp_array(test_labels.to_numpy().reshape((-1, 1)), context)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the weight\n",
    "\n",
    "The weights have to be crypted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 05:58:31 PM  [INFO    ]  [ 0.01408397 -0.17700907 -0.07331132  0.06680229  0.04806284  0.3112355\n",
      " -0.17367298 -0.3277617  -0.16719339 -0.44113512 -0.21578143 -0.26694345\n",
      " -0.01501394 -0.10192135 -0.05355695  0.07521127 -0.01471091  0.13245995\n",
      "  0.30348841  0.08252216  0.18796522  0.11776661  0.56398854  0.48696312\n",
      " -0.08711154  0.02219701 -0.12388879  0.18653506  0.20490487  0.00320036\n",
      "  0.20441375]\n",
      "07/22/2020 05:58:32 PM  [INFO    ]  [ 0.01059113 -0.11527769 -0.14612441 -0.18983843 -0.05135012  0.47580575\n",
      "  0.1711407  -0.15817059 -0.00751927  0.00915133  0.14116642 -0.11246926\n",
      "  0.04220041 -0.13010715  0.15913326  0.29055188  0.29453337 -0.12648306\n",
      "  0.07425612 -0.019725    0.15551957 -0.08088814 -0.19689032  0.02322098\n",
      "  0.31128688 -0.13226666 -0.09122786 -0.21878743  0.08142922  0.31945005\n",
      " -0.05596945]\n",
      "peak memory: 734.33 MiB, increment: 7.27 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "unencrypted_weight = np.random.normal(loc=0,\n",
    "                                      scale=0.2, size =(train_features.to_numpy().shape[1]))\n",
    "logging.info(unencrypted_weight)\n",
    "weight = ts.ckks_vector(context, unencrypted_weight)\n",
    "unencrypted_weight = np.array(unencrypted_weight)\n",
    "unencrypted_bias = np.random.random((1))\n",
    "bias = ts.ckks_vector(context, unencrypted_bias)\n",
    "unencrypted_bias = np.array(unencrypted_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidential data as yet stored into a dictionnary, and will be used during the training only by functions which are passed as arguments to the fit methods. This encapsulation of sensitive data will allows us to ensure security during training later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 733.20 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "confidential_data = {'context':context,\n",
    "                     'secret_key':secret_key, \n",
    "                     'unencrypted_X':train_features.to_numpy(),\n",
    "                     'unencrypted_Y':train_labels.to_numpy().reshape((-1, 1)) \n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 758.20 MiB, increment: 25.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "weight.dot(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the crypted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 05:58:38 PM  [INFO    ]  Model initialization\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Model initialization\")\n",
    "model = encrypted_LR.LogisticRegressionHE(init_weight=weight,\n",
    "                                          init_bias=bias,\n",
    "                                          refresh_function=refresh, \n",
    "                                          confidential_kwarg=confidential_data,\n",
    "                                          accuracy=accuracy,\n",
    "                                          verbose=VERBOSE,\n",
    "                                          save_weight=SAVE_WEIGHT,\n",
    "                                          max_epoch=EPOCH,\n",
    "                                          lr=LEARNING_RATE,\n",
    "                                          reg_para=REGULARIZATION_RATE,\n",
    "                                          n_jobs = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 05:58:38 PM  [INFO    ]  Training starting\n",
      "07/22/2020 05:58:39 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 05:58:44 PM  [INFO    ]  iteration number 1 is starting\n",
      "07/22/2020 05:58:46 PM  [INFO    ]  Loss : <_tenseal_cpp.CKKSVector object at 0x00000246E63C2FB0>.\n",
      "07/22/2020 05:58:47 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 05:58:52 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 05:58:58 PM  [INFO    ]  iteration number 3 is starting\n",
      "07/22/2020 05:59:00 PM  [INFO    ]  Loss : <_tenseal_cpp.CKKSVector object at 0x00000246E632B570>.\n",
      "07/22/2020 05:59:00 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 05:59:06 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 05:59:11 PM  [INFO    ]  iteration number 5 is starting\n",
      "07/22/2020 05:59:14 PM  [INFO    ]  Loss : <_tenseal_cpp.CKKSVector object at 0x00000246E6303D30>.\n",
      "07/22/2020 05:59:14 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 05:59:20 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 05:59:25 PM  [INFO    ]  iteration number 7 is starting\n",
      "07/22/2020 05:59:27 PM  [INFO    ]  Loss : <_tenseal_cpp.CKKSVector object at 0x00000246E63BB130>.\n",
      "07/22/2020 05:59:28 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 05:59:33 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 05:59:39 PM  [INFO    ]  iteration number 9 is starting\n",
      "07/22/2020 05:59:41 PM  [INFO    ]  Loss : <_tenseal_cpp.CKKSVector object at 0x00000246E63B88F0>.\n",
      "07/22/2020 05:59:42 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 05:59:47 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 05:59:53 PM  [INFO    ]  iteration number 11 is starting\n",
      "07/22/2020 05:59:55 PM  [INFO    ]  Loss : <_tenseal_cpp.CKKSVector object at 0x00000246E63B7BB0>.\n",
      "07/22/2020 05:59:55 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 06:00:01 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 06:00:06 PM  [INFO    ]  iteration number 13 is starting\n",
      "07/22/2020 06:00:09 PM  [INFO    ]  Loss : <_tenseal_cpp.CKKSVector object at 0x00000246E62E1F30>.\n",
      "07/22/2020 06:00:09 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 06:00:15 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 06:00:20 PM  [INFO    ]  iteration number 15 is starting\n",
      "07/22/2020 06:00:22 PM  [INFO    ]  Loss : <_tenseal_cpp.CKKSVector object at 0x00000246E631DAF0>.\n",
      "07/22/2020 06:00:23 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 06:00:28 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 06:00:34 PM  [INFO    ]  iteration number 17 is starting\n",
      "07/22/2020 06:00:36 PM  [INFO    ]  Loss : <_tenseal_cpp.CKKSVector object at 0x00000246E631B6B0>.\n",
      "07/22/2020 06:00:36 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 06:00:42 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      "07/22/2020 06:00:47 PM  [INFO    ]  iteration number 19 is starting\n",
      "07/22/2020 06:00:50 PM  [INFO    ]  Loss : <_tenseal_cpp.CKKSVector object at 0x00000246E63B88B0>.\n",
      "07/22/2020 06:00:50 PM  [WARNING ]  One tenseal object cannot be pickle, aborting the use of multiprocessing.\n",
      " 07/22/2020 06:00:56 PM  [INFO    ]  Training done. 137.0 seconds\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Training starting\")\n",
    "timer=time.time()\n",
    "%prun model.fit(encrypted_X, encrypted_Y)\n",
    "logging.info(\"Training done. \" + str(round(time.time() - timer, 0)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82970427 0.48622341]\n",
      "[1. 1.]\n",
      "07/22/2020 06:00:56 PM  [INFO    ]  Accuracy of encrypted model : 0.5 \n"
     ]
    }
   ],
   "source": [
    "acc = model.accuracy(unencrypted_X=test_features.to_numpy(), unencrypted_Y=test_labels.to_numpy().reshape((-1, 1)))\n",
    "print(test_labels.to_numpy())\n",
    "logging.info(\"Accuracy of encrypted model : %s \" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the unencrypted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 06:00:56 PM  [INFO    ]  Model initialization\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Model initialization\")\n",
    "unencrypted_model = unencrypted_LR.LogisticRegression(init_weight=unencrypted_weight,\n",
    "                                                      init_bias=unencrypted_bias,\n",
    "                                                      verbose=VERBOSE,\n",
    "                                                      save_weight= SAVE_WEIGHT,\n",
    "                                                      max_epoch=EPOCH,\n",
    "                                                      lr=LEARNING_RATE,\n",
    "                                                      reg_para=REGULARIZATION_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2020 06:00:56 PM  [INFO    ]  Training starting\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Training starting\")\n",
    "timer=time.time()\n",
    "unencrypted_model.fit(train_features.to_numpy(), train_labels.to_numpy().reshape((-1, 1)))\n",
    "logging.info(\"Training done. \" + str(round(time.time() - timer, 0)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = unencrypted_model.accuracy(test_features.to_numpy(), test_labels.to_numpy().reshape((-1, 1)))\n",
    "logging.info(\"Accuracy of unencrypted model : %s \" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unencrypted_model.true_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unencrypted_model.weight.dot(unencrypted_model.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encrypted and unencrypted losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i*VERBOSE for i in range(len(model.loss_list))], [i.decrypt()[0] for i in model.loss_list], label='cipherloss')\n",
    "plt.plot([i*VERBOSE for i in range(len(unencrypted_model.loss_list))], unencrypted_model.loss_list, label='plainloss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Losses evolution of both models')\n",
    "plt.legend(loc='best')\n",
    "[i.decrypt()[0] for i in model.loss_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unencrypted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i*VERBOSE for i in range(len(unencrypted_model.loss_list))], np.array(unencrypted_model.loss_list).reshape((-1)))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss evolution of unencrypted model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logging.info(\"Model initialization\")\n",
    "unencrypted_model = unencrypted_LR.LogisticRegression(init_weight=unencrypted_weight,\n",
    "                                                      init_bias=unencrypted_bias,\n",
    "                                                      verbose=VERBOSE,\n",
    "                                                      save_weight= SAVE_WEIGHT,\n",
    "                                                      max_epoch==EPOCH,\n",
    "                                                      lr=LEARNING_RATE,\n",
    "                                                      reg_para=REGULARIZATION_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative error between losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypted = [i.decrypt()[0] for i in model.loss_list]\n",
    "true_err = np.abs(np.array(decrypted) - np.array(unencrypted_model.loss_list))\n",
    "rel_err = true_err/np.linalg.norm(decrypted)\n",
    "rel_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot([i*VERBOSE for i in range(len(model.loss_list))],  rel_err)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Relative error on loss')\n",
    "plt.title('Relative error between encrypted loss and unencrypted loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative error between weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = encryption_error(model.weight_list,model.bias_list, unencrypted_model.weight_list,unencrypted_model.bias_list)\n",
    "plt.plot([i*VERBOSE for i in range(len(error_list))], error_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Relative error on weights')\n",
    "plt.title('Relative error between encrypted weights and unencrypted weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TenSEAL",
   "language": "python",
   "name": "tenseal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
