{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy-preserving machine learning with two agents\n",
    "## Using homomorphic encryption over the titanic challenge\n",
    "\n",
    "Author:\n",
    "\n",
    "Arthur Pignet - apignet@equancy.com\n",
    "    \n",
    "\n",
    "### Objectives\n",
    "This notebook aims to demonstrate the faisibility of private machine learning.\n",
    "\n",
    "We got two agents, Bob and Alice. Bob has data, and wants to extract value from it. But Bob has no clue about data science and needs someone to help him to properly exploite his data. Bob contacts Alice, data scientist, to do so. Here, Bob's project is to create a model that predicts which passengers survived the Titanic shipwreck. He initialy has a datase which contains the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not. As the Titanic was an european ship, these data are under the GRPD reglementation. \n",
    "\n",
    "Therefore the problematic is how Alice can do her job of datascientist without seeing the private data.\n",
    "\n",
    "A part of the answer relies in homomorphic encryption. This kind of encryption allows one to make computation on encrypted data, without decrypting it, to obtain encrypted result. \n",
    "\n",
    "Here Bob will preprocess his data, then will encrypt its using the CKKS encryption scheme.\n",
    "Alice will receive the encrypted data, and train a model on it. \n",
    "Finally Alice will be able to use this model to make (encrypted) prediction for Bob.\n",
    "Once the model trained, Bob will send new (encrypted) data, (like test data, or unlabeled data),and got a encrypted prediction from Alice, that he will be able to decrypt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook shows the Bob's side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "All modules are mandatory. Make sure to import them all by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import socket\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import tenseal as ts\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, accuracy_score\n",
    "                           \n",
    "os.chdir(\"/home/apignet/homomorphic-encryption/ckks_titanic/\")\n",
    "from src.features import build_features\n",
    "from src.communication import Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n",
    "\n",
    "The raw data location, the log file location, and the output directory location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = os.getcwd()\n",
    "SUBMISSION_PATH = WORKING_DIR+\"/data/submission/\"\n",
    "DATA_PATH = WORKING_DIR+\"/data/raw/\"            # whole data set\n",
    "#DATA_PATH = WORKING_DIR+\"/data/quick_demo/\"   # subset of the data set, with 15 train_samples and 5 test_samples\n",
    "\n",
    "\n",
    "LOG_PATH = WORKING_DIR+\"/reports/log/\"\n",
    "LOG_FILENAME = \"Bob\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log\n",
    "\n",
    "Log parameters, for the logging librairy. The log will be printed on the notebook and stored on a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileHandler = logging.FileHandler(\"{0}/{1}.log\".format(LOG_PATH, LOG_FILENAME))\n",
    "streamHandler = logging.StreamHandler(sys.stdout)\n",
    "logging.basicConfig(format=\"%(asctime)s  [%(levelname)-8.8s]  %(message)s\", \n",
    "                    datefmt='%m/%d/%Y %I:%M:%S %p', \n",
    "                    level = logging.INFO, \n",
    "                    handlers=[fileHandler, streamHandler]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Socket Variables\n",
    "\n",
    "Bob and Alice will communicate though the socket module, and so will use these parameters.\n",
    "The port is the port on which the communication is going to be made\n",
    "The packet_size defines the size (in bytes) of the batch that will be sent and received\n",
    "The sentinel is a binary that will be sent to warn the other side that the message is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = '127.0.0.1'  # The server's hostname or IP address\n",
    "PORT = 65431        # The port used by the server\n",
    "PACKETS_SIZE = 16384\n",
    "SENTINEL = b'BREAK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and processing the data\n",
    "\n",
    "Bob starts by loading the data, and preprocess it. For more infomations on preprocessing and feature engineering, see the notebook 1-ap-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/10/2020 12:28:07 PM  [INFO    ]  /home/apignet/homomorphic-encryption/ckks_titanic\n",
      "08/10/2020 12:28:07 PM  [INFO    ]  loading the data into memory (pandas df)\n",
      "08/10/2020 12:28:07 PM  [INFO    ]  Done\n",
      "08/10/2020 12:28:07 PM  [INFO    ]  making final data set from raw data\n",
      "08/10/2020 12:28:08 PM  [INFO    ]  Done\n",
      "peak memory: 165.64 MiB, increment: 12.99 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "logging.info(os.getcwd())\n",
    "raw_train, raw_test = build_features.data_import(DATA_PATH)\n",
    "train, submission_test = build_features.processing(raw_train, raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 15 % of the dataset as test set, and will send it to Alice only when the model had been trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 165.98 MiB, increment: 0.10 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "train, test = train_test_split(train, test_size=0.15)\n",
    "train_labels = train.Survived\n",
    "test_labels = test.Survived\n",
    "train_features = train.drop(\"Survived\", axis=1)\n",
    "test_features = test.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homomorphic encryption\n",
    "\n",
    "Homomorphic encryption allowing private computations on the encrypted data, without having to decrypt its. Here Bob will encrypt the data, and will had Alice made the computation (model training). Alice will never see the plain data, and thus the dataset will stay private. Besides, this king of encryption suffers from huge draw back, as increasing memory/time complexity, and limited calculus depth per ciphertext. Indeed, for most of the homomorphic encryption (HE) schemes, the number of operation (like multiplication and addition) is limited. After performing a finite number of multiplication on a ciphertext, one will not be able to decrypt it properly. Some schemes by pass this limitation, but always at important costs, in memory or time computation. \n",
    "\n",
    "### Choice of the encryption scheme \n",
    "\n",
    "The encryption will be done with the tenseal library, which is build on the top of the Microsoft SEAL software.\n",
    "The two encryption schemes avaible in SEAL are BFV and CKKS. Here, we choose to use the CKKS sheme, which is designed to made floating point operations, at the opposite of the BFV scheme, which handles only intergers. \n",
    "\n",
    "### Definition of safety parameters\n",
    "\n",
    "The choice of the safety parameters (poly_modulus_degree, coeff_mod_bit_sizes, and global_scale) is cruciale. It is them that will define the memory size of our ciphertext, the floating precision of our operations, and the calculus depth limite.\n",
    "\n",
    "A really good understanding of the CKKS scheme functionning is requiered to properly set up these parameters. \n",
    "\n",
    "In the CKKS scheme, the plaintext vextors are first converted into polynomials with integer coefficients, which are then map by a ring isomorphisme in the ring FORMULE ICI.\n",
    "\n",
    "The number of slots in a ciphertext is poly_modulus_degree / 2 and each slot encodes one real or complex number. While encoding a smaller vector, the SEAL CKKSEncoder will implicitly pad itwith zeros to full size (poly_modulus_degree / 2) when encoding. Thus, the memory size of a ciphertext is definied by the poly_modulus.\n",
    "\n",
    "Moreover, to convert the plaintext into polynomial, the floating-point coefficients of the input will be scaled up by the parameter gloabl_scale. The scale can be seen as determining the bit-precision of the encoding. The ismorphism will store our messages modulo coeff_modulus, so the scaled message must not get too close to the total size of coeff_modulus. Otherwise, the decrypted result will make no sense. Therefore, the choice of the scale will participate to the precision of our operations, and is strongly relies to the choice of the poly_modulus.  \n",
    "\n",
    "As ciphertext multiplications are done as polynomial multiplications, we need to relinearize the polynom to obtain a result that has the same size as the initial ciphertexts (In fact this operation is not mandatory, but is done after every mutiplication in our application. See the documentation for more information). It is done with a special key (relin_key), and as a side-effect, makes the scale dramaticly increase. The scale of any ciphertext must not get too close to the total size of coeff_modulus, or else the ciphertext simply runs out of room to store the scaled-up plaintext. The CKKS scheme provides a rescale functionality that can reduce the scale, and stabilize the scale expansion. \n",
    "\n",
    "This rescale operation removes the last of the primes from coeff_modulus, but as a side-effect it scales down the ciphertext by the removed prime. More precisely, suppose that the scale in a CKKS ciphertext is S, and the last prime in the current coeff_modulus (for the ciphertext) is P. Rescaling to the next level changes the scale to S/P, and removes the prime P from the coeff_modulus, as usual in modulus switching. The number of primes limits how many rescalings can be done, and thus limits the multiplicative depth of the computation. It is possible to choose the initial scale freely. One good strategy can be to is to set the initial scale S and primes P_i in the coeff_modulus to be very close to each other. If ciphertexts have scale S before multiplication, they have scale S^2 after multiplication, and S^2/P_i after rescaling. If all P_i are close to S, then S^2/P_i is close to S again. This way we stabilize the scales to be close to S throughout the computation. Generally, for a circuit of depth D, we need to rescale D times, i.e., we need to be able to remove D primes from the coefficient modulus. Once we have only one prime left in the coeff_modulus, the remaining prime must be larger than S by a few bits to preserve the pre-decimal-point value of the plaintext.\n",
    "\n",
    "sources : \n",
    "SEAL tutorials \n",
    "\n",
    "https://github.com/microsoft/SEAL/blob/master/native/examples/1_bfv_basics.cpp\n",
    "https://github.com/microsoft/SEAL/blob/master/native/examples/2_encoders.cpp               \n",
    "https://github.com/microsoft/SEAL/blob/master/native/examples/3_levels.cpp\n",
    "https://github.com/microsoft/SEAL/blob/master/native/examples/4_ckks_basics.cpp\n",
    "\n",
    "from https://github.com/microsoft/SEAL/blob/master/native/examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/10/2020 12:28:09 PM  [INFO    ]  Definition of safety parameters...\n",
      "08/10/2020 12:28:09 PM  [INFO    ]  Done. 0.31 seconds\n",
      "08/10/2020 12:28:09 PM  [INFO    ]  Generation of the secret key...\n",
      "08/10/2020 12:28:09 PM  [INFO    ]  Done. 0.0 seconds\n",
      "08/10/2020 12:28:09 PM  [INFO    ]  Generation of the Galois Key...\n",
      "08/10/2020 12:28:12 PM  [INFO    ]  Done. 3.3 seconds\n",
      "08/10/2020 12:28:12 PM  [INFO    ]  Generation of the Relin Key...\n",
      "08/10/2020 12:28:12 PM  [INFO    ]  Done. 0.13 seconds\n",
      "08/10/2020 12:28:12 PM  [INFO    ]  The context is now public, the context do not hold the secret key anymore, and decrypt    methods need the secret key to be provide,\n",
      "08/10/2020 12:28:12 PM  [INFO    ]  serialization of the context started...\n",
      "08/10/2020 12:29:01 PM  [INFO    ]  Serialization done in 48.882649421691895 seconds\n",
      "peak memory: 1593.52 MiB, increment: 1427.54 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "logging.info('Definition of safety parameters...')\n",
    "timer = time.time()\n",
    "\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, 16384, coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 40, 40,40, 60])\n",
    "context.global_scale = pow(2, 40)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context is the main tenseal object. When created, it holds the secret and public keys. So it is needed to encrypt a vector.We can add to this context the relin's and Galois' keys. These keys are mandatory for every computation, therefore every vector encrypted with a specific context holds as an attribut a pointeur on the context. Moreover,if the context is private (ie holds the secret key), the method decrypt() on a vector will not need the secret key, as it can be accessed with vector.context.secret_key.\n",
    "It really convenient for computations but raise on issue on serialization, as we will see later.\n",
    "\n",
    "Alice will need the relin's and Galois' keys, so Bob will send the context to Alice, obviously without the secret key. So Bob will store the secret key, and will have the context drop it. Then Bob can generate the relin/galois keys, and sent it to Alice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Generation of the secret key...')\n",
    "timer = time.time()\n",
    "secret_key = context.secret_key()\n",
    "context.make_context_public() #drop the relin keys, the galois keys, and the secret keys. \n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "logging.info('Generation of the Galois Key...')\n",
    "timer = time.time()\n",
    "context.generate_galois_keys(secret_key)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "logging.info('Generation of the Relin Key...')\n",
    "timer = time.time()\n",
    "context.generate_relin_keys(secret_key)\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "if context.is_public():\n",
    "    logging.info(\"The context is now public, the context do not hold the secret key anymore, and decrypt\\\n",
    "    methods need the secret key to be provide,\")\n",
    "logging.info(\"serialization of the context started...\")\n",
    "timer = time.time()\n",
    "b_context = context.serialize()\n",
    "logging.info(\"Serialization done in %s seconds\" %(time.time()-timer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esthablishing the communication with Alice\n",
    "\n",
    "The computation, the training of the model will be done by Alice. We need to esthablishe a communication between the two actors to pass encrypted data, encrypted prediction, and the keys which are mandatory for the computation (in fact Bob will pass the full public context (ie without the secret key).\n",
    "\n",
    "### Actors\n",
    "\n",
    "Here we use the homemade calss actors. When initialized an actor tries to connect to the adress/ort which is passed as parameter (client role). If nobody is listening, the actor bind a socket and listen to it, waiting for a actor. \n",
    "\n",
    "For the transmission, an actor sents packet of the size PACKET_SIZE, and wait that the other actor replied b'next', which means that the packet had been received, and that it is waiting for the next packet. If the message is not completely sent, the actors itere the process. Else, the transmiting actor sends b'DONE' to signal to the other actor that all the packets had been sent, and the full message can be deserialize, or use...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/06/2020 03:45:29 PM  [INFO    ]  Nobody is listening, binding a server...\n",
      "08/06/2020 03:45:34 PM  [INFO    ]  Connected by 127.0.0.1:49688\n"
     ]
    }
   ],
   "source": [
    "ALICE = Actors.Actor(HOST, PORT, PACKETS_SIZE, SENTINEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending the public context\n",
    "\n",
    "Alice needs the context. The context is already ready, it is public and holds the three keys needed by Alice. We first need to serialize it. Keep in mind that the context with these keys is heavy in memory (around 500 Mb if you did not change the safety parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/06/2020 02:31:04 PM  [INFO    ]  The context has been sent\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"serialization of the context started...\")\n",
    "timer = time.time()\n",
    "b_context = context.serialize()\n",
    "logging.info(\"Serialization done in %s seconds. Sending the context...\" %(time.time()-timer))\n",
    "ALICE.transmission(b_context)\n",
    "logging.info('The context has been sent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crypting, serializing and sending the crypted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are currectly pandas dataframe, but tenseal needs list as input. We first use numpy for reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/06/2020 02:31:04 PM  [INFO    ]  Data encryption/serialization/ transfert to Alice...\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Data encryption/serialization/ transfert to Alice...\")\n",
    "timer = time.time()\n",
    "\n",
    "plain_X = train_features.to_numpy().tolist()\n",
    "plain_Y = train_labels.to_numpy().reshape((-1,1)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first sending to Alice the amouth of data she is supposed to receive, and the number of features in it. \n",
    "\n",
    "The amouth of data is useful for Alice, to initialize variable and know when stop listening for message. Alice also needs the number of features to initialize the weight and bias. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALICE.transmission(pk.dumps(train_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While encrypting the data, we also serialize it, ie convert it in binary, which will be sent to Alice. \n",
    "\n",
    "It is interesting to denote that while being serialize, ckks vector drops its context. If we pickle it in the standart way, by serilaizing every attribute, we will serialize the context (500 Mb) for every vector. So we serialize the context, sent it, serialize the vectors, which drop the context reference during the process. When Alice will deserialize the Bob's encrypted data, she will provide the context which these vectors will use for computations.\n",
    "\n",
    "We want to sent to Alice a easy-to-read object, so we send a dictionary, with explicit keys(id, features, label). The \"id\" is here to allow Alice to shuffle the dataset, during multiprocessing for instance, and still recover the right label/prediction for the right data. \n",
    "\n",
    "We use the pickle module to serialize and deserialize the dict. As the tenseal vector cannot be serialize by pickle for the reasons we evocated few lines ago, we have to first serialize the tenseal object with their own methods, and then ask pickle to serialize a dict containing references to strings, int and binaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/06/2020 02:32:14 PM  [INFO    ]  25 % ...\n",
      "08/06/2020 02:33:20 PM  [INFO    ]  50 % ...\n",
      "08/06/2020 02:34:25 PM  [INFO    ]  75% ...\n",
      "08/06/2020 02:35:31 PM  [INFO    ]  Done. 266.58 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(plain_X)):\n",
    "    ser_enc_x = ts.ckks_vector(context, plain_X[i]).serialize()\n",
    "    ser_enc_y = ts.ckks_vector(context, plain_Y[i]).serialize()\n",
    "    \n",
    "    data = pk.dumps({'id':i,\n",
    "                     'X':ser_enc_x, \n",
    "                     'label':ser_enc_y\n",
    "                    })\n",
    "    ALICE.transmission(data)\n",
    "    \n",
    "    if i == len(plain_X) // 4:\n",
    "        logging.info(\"25 % ...\")\n",
    "    elif i == len(plain_X) // 2 :\n",
    "        logging.info(\"50 % ...\")\n",
    "    elif i == 3* len(plain_X)//4:\n",
    "        logging.info(\"75% ...\")\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "ALICE.transmission(b'DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refreshing the weight\n",
    "\n",
    "At this point Alice has recieved all she needs. Its work can begin. While training its models, Alice will probably need to make more computations than allowed by the safety parameters (here around 8 mutiplications are allowed before running out of scale). So in order to evaluate calculus circuit of arbitrary depth, Alice needs a \"refresh\" function, which reset this dept. To do so, Bob will listening to Alice, and when needed, Alice will sent a vector to Bob. Bob will deseriailize it, decrypt it, re-encrypt it, and after serializition, send it back to Alice. Therefore, Alice will receive a freshly encrypted vector, which she will be able to use. She never saw any secret key nor unencrypted data.\n",
    "\n",
    "When the training is done, Alice annonces to Bob to b'STOP_REFRESH'\n",
    "\n",
    "We can then skip to the next step, the evaluation of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/06/2020 02:36:20 PM  [INFO    ]  Alice says start_fitting\n",
      "08/06/2020 02:36:36 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:36:37 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:37:32 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:37:33 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:37:33 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:37:34 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:39:18 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:39:19 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:40:14 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:40:15 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:41:10 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:41:11 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:42:06 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:42:07 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:43:02 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:43:03 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:43:03 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:43:04 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:44:49 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:44:49 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:45:45 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:45:45 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:46:41 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:46:41 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:47:37 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:47:37 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:48:33 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:48:33 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:48:33 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:48:34 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:50:19 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:50:20 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:51:15 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:51:16 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:52:11 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:52:11 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:53:07 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:53:07 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:54:03 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:54:03 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:54:04 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:54:04 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:55:49 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:55:50 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:56:45 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:56:46 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:57:41 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:57:41 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:58:37 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:58:37 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:59:33 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:59:34 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:59:34 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 02:59:35 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:01:20 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:01:20 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:02:16 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:02:16 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:03:12 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:03:12 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:04:08 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:04:08 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:05:04 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:05:04 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:05:05 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:05:05 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:06:50 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:06:51 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:07:46 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:07:47 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:08:42 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:08:43 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:09:38 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:09:38 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:10:34 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:10:34 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:10:35 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:10:35 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:12:20 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:12:21 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:13:16 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:13:17 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:14:12 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:14:13 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:15:08 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:15:09 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:16:04 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:16:05 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:16:05 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:16:05 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:17:50 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:17:51 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:18:46 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:18:47 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:19:43 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:19:43 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:20:39 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:20:39 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:21:34 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:21:35 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:21:35 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:21:36 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:23:21 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:23:21 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:24:17 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:24:17 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:25:13 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:25:13 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:26:09 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:26:09 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:27:05 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:27:05 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:27:06 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:27:06 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:28:51 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:28:51 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:29:47 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:29:47 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:30:43 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:30:43 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:31:39 PM  [INFO    ]  refreshing a vector...\n",
      "08/06/2020 03:31:39 PM  [INFO    ]  refreshing a vector...\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Alice says \"+str(ALICE.reception().decode()))\n",
    "while True:\n",
    "    b_data = ALICE.reception()\n",
    "    if b_data == b'STOP_REFRESH': break\n",
    "    logging.info(\"refreshing a vector...\")\n",
    "    vector = ts.ckks_vector_from(context, b_data)\n",
    "    decrypted_vector = vector.decrypt(secret_key)\n",
    "    refreshed_vector = ts.ckks_vector(context, decrypted_vector)\n",
    "    ALICE.transmission(refreshed_vector.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the loss back\n",
    "\n",
    "During the training, Alice computed loss. Nevertheless, the loss values are encrypted so she cannot use it at all, so she sent it to Bob for plotting.\n",
    "\n",
    "Here there is a potential security leack. The loss graphic cannot be sent to Alice, otherwise Alice will have access to a kind of decrypt method. If Alice decide to sent not the loss, but a fake loss constitued with some interesting values (encrypted) to Bob, and Bob send the decrypted fake loss to Alice, Alice will have acess to these sensitive values. \n",
    "\n",
    "So even a normalize figure cannot be sent to Alice. Bob will be the only one who can look at the loss (Maybe not ht eonly one, but he cannot sent it back to ALice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch, enc_loss = pk.loads(ALICE.reception())\n",
    "loss = [ts.ckks_vector_from(context,l).decrypt(secret_key)[0] for l in enc_loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Alice to make prediction\n",
    "\n",
    "As Bob was previously continuously listening for vector to refresh, now Alice is listening to Bob, waiting for data to do inference on it. So Bob will use Alice's model to make predictions over a test set, and after getting a good evaluation of Alice's model, he will sent fresh data, to get predictions.\n",
    "\n",
    "It is important to denote that, even if we spoke only of predictions, Alice does not really sent predictions, but probability. The output of Alice model corresponds to the probability of being in the class 1. Bob can round the decrypted result to get the label prediction (0 if the probability is above 0.5, and 1 if it is higher). One can choose to use a threshold differente from 0.5, for instance if less risk on the prediction of one class is needed. This choice has to be made by Bob, as Alice cannot do comparison between ciphertext. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/06/2020 03:31:40 PM  [INFO    ]  Data encryption/serialization/ transfert to Alice...\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Test data encryption/serialization/ transfert to Alice...\")\n",
    "timer = time.time()\n",
    "\n",
    "plain_test_X = test_features.to_numpy().tolist()\n",
    "proba_predictions = [None for _ in range(len(plain_test_X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/06/2020 03:31:40 PM  [INFO    ]  Asking Alice for prediction\n",
      "08/06/2020 03:32:47 PM  [INFO    ]  Done. 67.47 seconds\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Asking Alice for prediction\")\n",
    "timer = time.time()\n",
    "for i in range(len(plain_test_X)):\n",
    "    ser_enc_x = ts.ckks_vector(context, plain_test_X[i]).serialize()\n",
    "    data = pk.dumps([i,ser_enc_x])\n",
    "    ALICE.transmission(data)\n",
    "    key, enc_ser_pred = pk.loads(ALICE.reception())\n",
    "    proba_predictions[key] = ts.ckks_vector_from(context, enc_ser_pred).decrypt(secret_key)\n",
    "    if i == len(plain_X) // 4:\n",
    "        logging.info(\"25 % ...\")\n",
    "    elif i == len(plain_X) // 2 :\n",
    "        logging.info(\"50 % ...\")\n",
    "    elif i == 3* len(plain_X)//4:\n",
    "        logging.info(\"75% ...\")\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "assert not (None in proba_predictions), 'Missing predictions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the model\n",
    "\n",
    "Once Bob got predictions on test set and loss, he can evaluate some metrics on Alice's model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss evolution over epochs')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch,\n",
    "         loss)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss evolution over epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/06/2020 03:32:47 PM  [INFO    ]  Precision score of encrypted model on test set: 0.7333333333333333 \n",
      "08/06/2020 03:32:47 PM  [INFO    ]  Recall score  of encrypted model on test set : 0.6470588235294118 \n",
      "08/06/2020 03:32:47 PM  [INFO    ]  F1 score of encrypted model on test set: 0.6875 \n",
      "08/06/2020 03:32:47 PM  [INFO    ]  Accuracy of encrypted model on train set : 0.7938144329896907 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = 1*(np.array(proba_predictions) > 0.5)\n",
    "recall = recall_score(test_labels,prediction)\n",
    "F1 = f1_score(test_labels, prediction)\n",
    "precision = precision_score(test_labels, prediction)\n",
    "cf_m=confusion_matrix(test_labels, prediction ) \n",
    "accuracy = accuracy_score(test_labels, prediction)\n",
    "\n",
    "logging.info(\"Precision score of encrypted model on test set: %s \" % precision)\n",
    "logging.info(\"Recall score  of encrypted model on test set : %s \" % recall)\n",
    "logging.info(\"F1 score of encrypted model on test set: %s \" % F1)\n",
    "logging.info(\"Accuracy of encrypted model on test set : %s \" % accuracy)\n",
    "sns.heatmap(cf_m, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here Bob can be satisfied, the model has a quite good accuracy, even if the F1 score is not that high. Nevertheless, these metrics satisfied Bob, so he decides to use Alice's model to do some real/useful predictions. \n",
    "\n",
    "For that, he has a data set, with unlabelled data. Alice is still listening for data to predict on. So like before, Bob sent the encrypted unlabelled data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/06/2020 03:45:55 PM  [INFO    ]  New data encryption/serialization/ transfert to Alice for prediction...\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"New data encryption/serialization/ transfert to Alice for prediction...\")\n",
    "timer = time.time()\n",
    "\n",
    "plain_test_X = submission_test.to_numpy().tolist()\n",
    "proba_predictions = [None for _ in range(len(plain_test_X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/06/2020 03:45:57 PM  [INFO    ]  Asking Alice for prediction on the new data\n",
      "08/06/2020 03:47:32 PM  [INFO    ]  25 % ...\n",
      "08/06/2020 03:49:07 PM  [INFO    ]  50 % ...\n",
      "08/06/2020 03:50:42 PM  [INFO    ]  75% ...\n",
      "08/06/2020 03:50:48 PM  [INFO    ]  Done. 290.9 seconds\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Asking Alice for prediction on the new data\")\n",
    "timer = time.time()\n",
    "for i in range(len(plain_test_X)):\n",
    "    ser_enc_x = ts.ckks_vector(context, plain_test_X[i]).serialize()\n",
    "    data = pk.dumps([i,ser_enc_x])\n",
    "    ALICE.transmission(data)\n",
    "    key, enc_ser_pred = pk.loads(ALICE.reception())\n",
    "    proba_predictions[key] = ts.ckks_vector_from(context, enc_ser_pred).decrypt(secret_key)\n",
    "    if i == len(plain_X) // 4:\n",
    "        logging.info(\"25 % ...\")\n",
    "    elif i == len(plain_X) // 2 :\n",
    "        logging.info(\"50 % ...\")\n",
    "    elif i == 3* len(plain_X)//4:\n",
    "        logging.info(\"75% ...\")\n",
    "logging.info(\"Done. \" + str(round(time.time() - timer, 2)) + \" seconds\")\n",
    "assert not (None in proba_predictions), 'Missing predictions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Bob has all the predictions he needed, so he informs Alice that he no longer requiere her prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALICE.transmission(b'STOP_PREDICT')\n",
    "ALICE.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bob can now decrypt the result, and export a good looking dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d7d890de2fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba_predictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m submission_df = pd.DataFrame({\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m\"PassengerId\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mraw_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PassengerId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msubmission_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "submission_pred = 1*(np.array(proba_predictions) > 0.5)\n",
    "submission_df = pd.DataFrame({\n",
    "        \"PassengerId\": raw_test[\"PassengerId\"],\n",
    "        \"Survived\": submission_pred.reshape(-1)\n",
    "    })\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(SUBMISSION_PATH+'first_sub_alice_bob2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
